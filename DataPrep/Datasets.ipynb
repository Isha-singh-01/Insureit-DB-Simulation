{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeec58c5-7bd9-4583-ba52-84e97ac4f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d70b83-9a9d-4684-b74e-ebd4f04959d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.read_csv('customer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad62e2d-72c0-4659-9e5d-409a0b92d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer.head()\n",
    "customer.drop(['First Name','Last Name'], axis=1, inplace = True)\n",
    "customer.rename(columns = {'id':'Customer_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03474e5d-7b49-43de-8a43-3e0b77ac09c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Address</th>\n",
       "      <th>Driving_licence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987673</td>\n",
       "      <td>Bidget Keaton</td>\n",
       "      <td>778-475-2740</td>\n",
       "      <td>bkeaton0@netvibes.com</td>\n",
       "      <td>4134 Jenifer Circle</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352841</td>\n",
       "      <td>Roderigo Sends</td>\n",
       "      <td>865-535-4858</td>\n",
       "      <td>rsends1@elegantthemes.com</td>\n",
       "      <td>73 Kenwood Terrace</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554593</td>\n",
       "      <td>Germain Metzig</td>\n",
       "      <td>782-318-0312</td>\n",
       "      <td>gmetzig2@discuz.net</td>\n",
       "      <td>94 Hoepker Hill</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>778711</td>\n",
       "      <td>Hattie Kevern</td>\n",
       "      <td>564-480-9848</td>\n",
       "      <td>hkevern3@nyu.edu</td>\n",
       "      <td>40 Valley Edge Circle</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78932</td>\n",
       "      <td>Dorena Kingaby</td>\n",
       "      <td>370-179-1371</td>\n",
       "      <td>dkingaby4@printfriendly.com</td>\n",
       "      <td>13765 Petterle Circle</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_id            Name         Phone                        Email  \\\n",
       "0       987673   Bidget Keaton  778-475-2740        bkeaton0@netvibes.com   \n",
       "1       352841  Roderigo Sends  865-535-4858    rsends1@elegantthemes.com   \n",
       "2       554593  Germain Metzig  782-318-0312          gmetzig2@discuz.net   \n",
       "3       778711   Hattie Kevern  564-480-9848             hkevern3@nyu.edu   \n",
       "4        78932  Dorena Kingaby  370-179-1371  dkingaby4@printfriendly.com   \n",
       "\n",
       "                 Address Driving_licence  \n",
       "0    4134 Jenifer Circle             Yes  \n",
       "1     73 Kenwood Terrace             Yes  \n",
       "2        94 Hoepker Hill              No  \n",
       "3  40 Valley Edge Circle             Yes  \n",
       "4  13765 Petterle Circle             Yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28112cc-158d-454a-9e7e-fa2fa063ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance = pd.read_csv('finance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd731cd-1393-4097-a316-a991719c36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance.rename(columns = {'Annual Income':'Income','Account Number':'Account_number'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec221678-9a04-403a-a60e-4b411707afbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Income</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Account_number</th>\n",
       "      <th>Bank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987673</td>\n",
       "      <td>224-48-7837</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>Good</td>\n",
       "      <td>6247488842</td>\n",
       "      <td>Chase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352841</td>\n",
       "      <td>477-90-5881</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>Good</td>\n",
       "      <td>8017327721</td>\n",
       "      <td>Wells Fargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554593</td>\n",
       "      <td>331-60-5414</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>Good</td>\n",
       "      <td>1463973416</td>\n",
       "      <td>Bank of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>778711</td>\n",
       "      <td>180-88-7800</td>\n",
       "      <td>30689.89</td>\n",
       "      <td>Good</td>\n",
       "      <td>6120588712</td>\n",
       "      <td>Citigroup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78932</td>\n",
       "      <td>853-17-1579</td>\n",
       "      <td>4148862.00</td>\n",
       "      <td>Good</td>\n",
       "      <td>6663340180</td>\n",
       "      <td>TD Bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_id          SSN      Income Credit_History  Account_number  \\\n",
       "0       987673  224-48-7837    19114.12           Good      6247488842   \n",
       "1       352841  477-90-5881    34847.84           Good      8017327721   \n",
       "2       554593  331-60-5414   143162.64           Good      1463973416   \n",
       "3       778711  180-88-7800    30689.89           Good      6120588712   \n",
       "4        78932  853-17-1579  4148862.00           Good      6663340180   \n",
       "\n",
       "              Bank  \n",
       "0            Chase  \n",
       "1      Wells Fargo  \n",
       "2  Bank of America  \n",
       "3        Citigroup  \n",
       "4          TD Bank  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d03e8c2-8b99-438a-91bc-387b753a625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance['SSN'] = finance['SSN'].str.replace('-','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8da4f07-9976-41a2-b7d8-9ba25f5b5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = pd.read_csv('AGENTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241cb1a5-510b-49bf-815d-027efd7be501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97444</td>\n",
       "      <td>Eolanda Tillerton</td>\n",
       "      <td>530-528-4376</td>\n",
       "      <td>etillerton0@nydailynews.com</td>\n",
       "      <td>512292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80340</td>\n",
       "      <td>Lynnell Pixton</td>\n",
       "      <td>297-990-1742</td>\n",
       "      <td>lpixton1@yellowbook.com</td>\n",
       "      <td>852715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6768</td>\n",
       "      <td>Brunhilda Smyley</td>\n",
       "      <td>611-265-3125</td>\n",
       "      <td>bsmyley2@topsy.com</td>\n",
       "      <td>547082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52121</td>\n",
       "      <td>Kaitlin Ruter</td>\n",
       "      <td>188-177-5814</td>\n",
       "      <td>kruter3@wikimedia.org</td>\n",
       "      <td>525745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85926</td>\n",
       "      <td>Joshuah Devas</td>\n",
       "      <td>820-918-3141</td>\n",
       "      <td>jdevas4@google.es</td>\n",
       "      <td>734363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agent_ID               Name         Phone                        Email  \\\n",
       "0     97444  Eolanda Tillerton  530-528-4376  etillerton0@nydailynews.com   \n",
       "1     80340     Lynnell Pixton  297-990-1742      lpixton1@yellowbook.com   \n",
       "2      6768   Brunhilda Smyley  611-265-3125           bsmyley2@topsy.com   \n",
       "3     52121      Kaitlin Ruter  188-177-5814        kruter3@wikimedia.org   \n",
       "4     85926      Joshuah Devas  820-918-3141            jdevas4@google.es   \n",
       "\n",
       "   Salary  \n",
       "0  512292  \n",
       "1  852715  \n",
       "2  547082  \n",
       "3  525745  \n",
       "4  734363  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89aa8a54-0988-4b00-b70c-e8b755b84528",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan = pd.read_csv('loan.csv')\n",
    "loan.head()\n",
    "loan.drop(['Loan_Amount_Term','Credit_History','Property_Area'],axis=1,inplace=True)\n",
    "loan = loan.iloc[:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77368b58-a23b-45cc-92b8-2a5c51505bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan['Customer_id'] = loan['Customer_id'].astype(int)\n",
    "loan['Tenure'] = loan['Tenure'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3460f92-b86e-4c3e-86e0-bd55edd9338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               object\n",
       "LoanAmount ('000)    float64\n",
       "Customer_id            int64\n",
       "Tenure                 int64\n",
       "LoanType              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40a03dc-c056-4de6-9768-20ac747fa9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan['Customer_id'] = loan['Customer_id'].astype(str)\n",
    "loan['Tenure'] = loan['Tenure'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b8f0d76-cd80-4a91-93da-d2c3a7e0f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.rename(columns = {\"LoanAmount ('000)\":\"LoanAmount\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f4b84c6-403d-48de-8815-309019f829f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan['LoanAmount'] = loan['LoanAmount']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52dfa919-8b22-4836-98bc-1dacd9eedbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>LoanType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>987673</td>\n",
       "      <td>30</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>987673</td>\n",
       "      <td>30</td>\n",
       "      <td>Vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>352841</td>\n",
       "      <td>30</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>554593</td>\n",
       "      <td>30</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>554593</td>\n",
       "      <td>30</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  LoanAmount Customer_id Tenure LoanType\n",
       "0  LP001015    110000.0      987673     30     Home\n",
       "1  LP001022    126000.0      987673     30  Vehicle\n",
       "2  LP001031    208000.0      352841     30     Home\n",
       "3  LP001035    100000.0      554593     30     Home\n",
       "4  LP001051     78000.0      554593     30     Home"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9167b4af-8706-4265-869c-23785c941a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mysql.connector import connect, Error\n",
    "# from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d103d4-585d-42e0-80e9-9aa7dca4983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     conn = connect (\n",
    "#        host = 'localhost',\n",
    "#        username = input('Enter your username'),\n",
    "#        password = input('Enter your password'),\n",
    "#        database = 'insurit'\n",
    "#     )\n",
    "# except Error as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a920324-8e4b-43e8-9950-eb3ba7c557ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d699af-a427-4049-b73b-788e882e89ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Agents VALUES (97444, 'Eolanda Tillerton', '530-528-4376', 'etillerton0@nydailynews.com', 512292);\n",
      "INSERT INTO Agents VALUES (80340, 'Lynnell Pixton', '297-990-1742', 'lpixton1@yellowbook.com', 852715);\n",
      "INSERT INTO Agents VALUES (6768, 'Brunhilda Smyley', '611-265-3125', 'bsmyley2@topsy.com', 547082);\n",
      "INSERT INTO Agents VALUES (52121, 'Kaitlin Ruter', '188-177-5814', 'kruter3@wikimedia.org', 525745);\n",
      "INSERT INTO Agents VALUES (85926, 'Joshuah Devas', '820-918-3141', 'jdevas4@google.es', 734363);\n",
      "INSERT INTO Agents VALUES (73812, 'Bertha Gibbe', '688-502-8799', 'bgibbe5@mapquest.com', 820523);\n",
      "INSERT INTO Agents VALUES (95189, 'Stefa Cours', '882-723-7290', 'scours6@odnoklassniki.ru', 755473);\n",
      "INSERT INTO Agents VALUES (92085, 'Erinn Minchindon', '436-379-1334', 'eminchindon7@theatlantic.com', 318714);\n",
      "INSERT INTO Agents VALUES (92900, 'Rhonda Mayhead', '881-274-4756', 'rmayhead8@bloomberg.com', 400885);\n",
      "INSERT INTO Agents VALUES (69259, 'Bonnibelle Manchett', '839-488-0561', 'bmanchett9@buzzfeed.com', 552776);\n",
      "INSERT INTO Agents VALUES (13041, 'Raddie Basson', '560-368-3460', 'rbassona@psu.edu', 300977);\n",
      "INSERT INTO Agents VALUES (78600, 'Veronika Pestricke', '832-194-4030', 'vpestrickeb@hhs.gov', 295584);\n",
      "INSERT INTO Agents VALUES (33645, 'Worden Rosedale', '342-776-4301', 'wrosedalec@over-blog.com', 163238);\n",
      "INSERT INTO Agents VALUES (47590, 'Windy Abden', '682-657-9610', 'wabdend@sbwire.com', 888306);\n",
      "INSERT INTO Agents VALUES (54342, 'Gordon Darrel', '454-219-8925', 'gdarrele@businesswire.com', 561510);\n",
      "INSERT INTO Agents VALUES (74988, 'Jess Sheavills', '812-721-0400', 'jsheavillsf@shop-pro.jp', 830578);\n",
      "INSERT INTO Agents VALUES (39178, 'Johnette Haller', '774-832-1487', 'jhallerg@ebay.com', 152279);\n",
      "INSERT INTO Agents VALUES (30720, 'Gabriella Baitey', '115-639-0792', 'gbaiteyh@wikipedia.org', 849936);\n",
      "INSERT INTO Agents VALUES (4629, 'Shea Scrowton', '242-123-8721', 'sscrowtoni@plala.or.jp', 579882);\n",
      "INSERT INTO Agents VALUES (96845, 'Juana Burberow', '993-581-2133', 'jburberowj@illinois.edu', 708124);\n",
      "INSERT INTO Agents VALUES (66218, 'Ezra Georger', '286-372-2813', 'egeorgerk@ow.ly', 512072);\n",
      "INSERT INTO Agents VALUES (97840, 'Nert Stockill', '666-702-4417', 'nstockilll@theguardian.com', 219810);\n",
      "INSERT INTO Agents VALUES (35917, 'Faina Spring', '793-203-8997', 'fspringm@newyorker.com', 402620);\n",
      "INSERT INTO Agents VALUES (49539, 'Creigh Phlippi', '380-624-9586', 'cphlippin@google.cn', 292520);\n",
      "INSERT INTO Agents VALUES (80633, 'Annalee Esp', '294-763-5480', 'aespo@ftc.gov', 345017);\n",
      "INSERT INTO Agents VALUES (92786, 'Hayyim Niave', '235-911-9074', 'hniavep@printfriendly.com', 612290);\n",
      "INSERT INTO Agents VALUES (68833, 'Reider Plows', '346-360-7174', 'rplowsq@goo.gl', 290837);\n",
      "INSERT INTO Agents VALUES (71268, 'Oliver Heaney', '700-767-1280', 'oheaneyr@umich.edu', 784328);\n",
      "INSERT INTO Agents VALUES (80048, 'Quent Beeble', '490-514-1132', 'qbeebles@squarespace.com', 402270);\n",
      "INSERT INTO Agents VALUES (31957, 'Lesli Couronne', '548-508-9555', 'lcouronnet@dedecms.com', 835102);\n",
      "INSERT INTO Agents VALUES (88459, 'Sayres Polglaze', '169-510-7179', 'spolglazeu@hp.com', 625865);\n",
      "INSERT INTO Agents VALUES (58102, 'Grantley Livingston', '324-862-1801', 'glivingstonv@bizjournals.com', 745480);\n",
      "INSERT INTO Agents VALUES (125, 'Amelina Swinyard', '890-432-6030', 'aswinyardw@topsy.com', 402048);\n",
      "INSERT INTO Agents VALUES (56777, 'Felicia Maxworthy', '279-934-5400', 'fmaxworthyx@ycombinator.com', 585696);\n",
      "INSERT INTO Agents VALUES (11119, 'Annice Trewhella', '479-720-1862', 'atrewhellay@delicious.com', 706300);\n",
      "INSERT INTO Agents VALUES (66624, 'Keir Swallwell', '906-651-8207', 'kswallwellz@shop-pro.jp', 693586);\n",
      "INSERT INTO Agents VALUES (95587, 'Jobina Toor', '618-787-6209', 'jtoor10@w3.org', 158833);\n",
      "INSERT INTO Agents VALUES (46129, 'Madlen D'Agostini', '656-131-0352', 'mdagostini11@wikia.com', 275629);\n",
      "INSERT INTO Agents VALUES (62599, 'Forster Manntschke', '635-505-4502', 'fmanntschke12@paypal.com', 760910);\n",
      "INSERT INTO Agents VALUES (38302, 'Florencia Coppard', '872-211-7033', 'fcoppard13@comcast.net', 234042);\n",
      "INSERT INTO Agents VALUES (62068, 'Cherish Dyball', '938-934-3347', 'cdyball14@squidoo.com', 870681);\n",
      "INSERT INTO Agents VALUES (76607, 'Kelvin Rekes', '999-647-8148', 'krekes15@storify.com', 497158);\n",
      "INSERT INTO Agents VALUES (2340, 'Eddie Gimson', '672-601-2701', 'egimson16@de.vu', 387427);\n",
      "INSERT INTO Agents VALUES (85484, 'Danyelle Trebilcock', '653-438-5978', 'dtrebilcock17@goodreads.com', 412469);\n",
      "INSERT INTO Agents VALUES (27853, 'Chryste Windmill', '906-939-2362', 'cwindmill18@indiatimes.com', 729213);\n",
      "INSERT INTO Agents VALUES (16339, 'Wildon Vaudre', '151-421-6581', 'wvaudre19@hatena.ne.jp', 174887);\n",
      "INSERT INTO Agents VALUES (24998, 'Englebert Stenton', '317-998-9059', 'estenton1a@pcworld.com', 627117);\n",
      "INSERT INTO Agents VALUES (47781, 'Anthiathia Rickersey', '325-295-6499', 'arickersey1b@howstuffworks.com', 647817);\n",
      "INSERT INTO Agents VALUES (39992, 'Konstance Mariotte', '375-920-3091', 'kmariotte1c@webeden.co.uk', 780748);\n",
      "INSERT INTO Agents VALUES (31487, 'Cairistiona Reardon', '979-143-2164', 'creardon1d@eepurl.com', 737356);\n"
     ]
    }
   ],
   "source": [
    "for Agent_ID, Name, Phone, Email, Salary in agents.values.tolist():\n",
    "    print(\"INSERT INTO Agents VALUES ({}, '{}', '{}', '{}', {});\".format(Agent_ID, Name, Phone, Email, Salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d935a462-9dbd-496b-8f36-c58015cf303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Customer VALUES (987673, 'Bidget Keaton', '778-475-2740', 'bkeaton0@netvibes.com', '4134 Jenifer Circle', 'Yes');\n",
      "INSERT INTO Customer VALUES (352841, 'Roderigo Sends', '865-535-4858', 'rsends1@elegantthemes.com', '73 Kenwood Terrace', 'Yes');\n",
      "INSERT INTO Customer VALUES (554593, 'Germain Metzig', '782-318-0312', 'gmetzig2@discuz.net', '94 Hoepker Hill', 'No');\n",
      "INSERT INTO Customer VALUES (778711, 'Hattie Kevern', '564-480-9848', 'hkevern3@nyu.edu', '40 Valley Edge Circle', 'Yes');\n",
      "INSERT INTO Customer VALUES (78932, 'Dorena Kingaby', '370-179-1371', 'dkingaby4@printfriendly.com', '13765 Petterle Circle', 'Yes');\n",
      "INSERT INTO Customer VALUES (319355, 'Leda Liffe', '768-317-1479', 'lliffe5@sun.com', '17870 Oxford Plaza', 'Yes');\n",
      "INSERT INTO Customer VALUES (719439, 'Hailey Titchener', '160-664-3603', 'htitchener6@cnet.com', '33085 Meadow Vale Way', 'Yes');\n",
      "INSERT INTO Customer VALUES (538409, 'Alyse Volleth', '977-218-2551', 'avolleth7@hhs.gov', '10 Kipling Court', 'No');\n",
      "INSERT INTO Customer VALUES (979749, 'Thalia Raitie', '846-557-5060', 'traitie8@comcast.net', '3 Melody Circle', 'No');\n",
      "INSERT INTO Customer VALUES (640537, 'Constanta Beresfore', '453-864-6762', 'cberesfore9@cargocollective.com', '35432 Charing Cross Avenue', 'No');\n",
      "INSERT INTO Customer VALUES (871428, 'Elfreda Callander', '143-883-7368', 'ecallandera@gnu.org', '8828 Forest Run Avenue', 'No');\n",
      "INSERT INTO Customer VALUES (847339, 'Brittney Mash', '690-401-9216', 'bmashb@nationalgeographic.com', '24753 Walton Trail', 'Yes');\n",
      "INSERT INTO Customer VALUES (94613, 'Cassandra Veitch', '312-814-1819', 'cveitchc@cbslocal.com', '850 Monument Avenue', 'Yes');\n",
      "INSERT INTO Customer VALUES (628418, 'Sianna Scay', '128-774-9848', 'sscayd@nps.gov', '9230 Waxwing Hill', 'Yes');\n",
      "INSERT INTO Customer VALUES (974101, 'Carlo Grimm', '786-476-8508', 'cgrimme@house.gov', '601 Upham Center', 'Yes');\n",
      "INSERT INTO Customer VALUES (930301, 'Hoebart Guidone', '751-282-1295', 'hguidonef@hubpages.com', '78 Thompson Hill', 'No');\n",
      "INSERT INTO Customer VALUES (915790, 'Erina Neligan', '755-787-5609', 'eneligang@delicious.com', '7 Summit Trail', 'Yes');\n",
      "INSERT INTO Customer VALUES (389080, 'Maurita Kleinplatz', '152-738-5550', 'mkleinplatzh@vimeo.com', '69920 Golf View Terrace', 'No');\n",
      "INSERT INTO Customer VALUES (336850, 'Arda Calderhead', '139-697-7506', 'acalderheadi@indiatimes.com', '736 Sauthoff Point', 'Yes');\n",
      "INSERT INTO Customer VALUES (176254, 'Correna Stitch', '602-865-3223', 'cstitchj@tripod.com', '15296 Bartillon Park', 'Yes');\n",
      "INSERT INTO Customer VALUES (638484, 'Angie Attow', '343-925-7380', 'aattowk@mapy.cz', '05 Summerview Junction', 'Yes');\n",
      "INSERT INTO Customer VALUES (621200, 'Augie Chene', '745-190-9290', 'achenel@omniture.com', '766 4th Parkway', 'Yes');\n",
      "INSERT INTO Customer VALUES (555849, 'Rochette Dowglass', '231-251-7850', 'rdowglassm@exblog.jp', '7906 Marcy Place', 'Yes');\n",
      "INSERT INTO Customer VALUES (972654, 'Berkly O'Glessane', '326-742-8192', 'boglessanen@chicagotribune.com', '42236 Clove Plaza', 'Yes');\n",
      "INSERT INTO Customer VALUES (492977, 'Darb Tomsen', '658-767-5430', 'dtomseno@mashable.com', '31 Forest Run Alley', 'No');\n",
      "INSERT INTO Customer VALUES (77471, 'Guthrie Cortese', '770-414-1691', 'gcortesep@about.com', '0077 Sheridan Drive', 'No');\n",
      "INSERT INTO Customer VALUES (289060, 'Aundrea Abrahmer', '470-635-1811', 'aabrahmerq@yelp.com', '600 Haas Terrace', 'No');\n",
      "INSERT INTO Customer VALUES (166248, 'Gisela Kretchmer', '668-244-2155', 'gkretchmerr@list-manage.com', '64 Pawling Way', 'No');\n",
      "INSERT INTO Customer VALUES (830875, 'Hendrika Keynes', '174-384-6234', 'hkeyness@businessinsider.com', '1 Sommers Way', 'No');\n",
      "INSERT INTO Customer VALUES (591642, 'Derrick Vowells', '336-654-2002', 'dvowellst@cyberchimps.com', '77236 Hazelcrest Trail', 'No');\n",
      "INSERT INTO Customer VALUES (293654, 'Thomasin Boddymead', '867-190-2098', 'tboddymeadu@domainmarket.com', '618 Hanover Street', 'Yes');\n",
      "INSERT INTO Customer VALUES (532909, 'Flo Mackett', '412-351-4643', 'fmackettv@princeton.edu', '06 Longview Street', 'Yes');\n",
      "INSERT INTO Customer VALUES (109075, 'Darrel Gounot', '993-434-7131', 'dgounotw@gizmodo.com', '4 West Way', 'Yes');\n",
      "INSERT INTO Customer VALUES (174408, 'Harri Paolo', '790-698-5891', 'hpaolox@marriott.com', '3 Cordelia Center', 'No');\n",
      "INSERT INTO Customer VALUES (632251, 'Bendicty Gogay', '162-986-3633', 'bgogayy@toplist.cz', '164 Forest Plaza', 'Yes');\n",
      "INSERT INTO Customer VALUES (981115, 'Antonius Freschini', '600-340-9348', 'afreschiniz@behance.net', '610 Transport Parkway', 'Yes');\n",
      "INSERT INTO Customer VALUES (58082, 'Alfred Balshen', '140-400-3125', 'abalshen10@bloglines.com', '0 Glendale Parkway', 'Yes');\n",
      "INSERT INTO Customer VALUES (499661, 'Edy Toulamain', '302-814-3607', 'etoulamain11@irs.gov', '17892 Fairview Junction', 'No');\n",
      "INSERT INTO Customer VALUES (950610, 'Hilary Pockett', '278-453-0517', 'hpockett12@dailymail.co.uk', '3323 International Road', 'Yes');\n",
      "INSERT INTO Customer VALUES (358893, 'Kara-lynn Dallaway', '579-654-3410', 'kdallaway13@bbc.co.uk', '4 Milwaukee Park', 'Yes');\n",
      "INSERT INTO Customer VALUES (867938, 'Ricki Rayner', '643-725-5750', 'rrayner14@alexa.com', '956 Loftsgordon Point', 'Yes');\n",
      "INSERT INTO Customer VALUES (114971, 'Reeva Kupisz', '300-253-6630', 'rkupisz15@moonfruit.com', '6910 Bluestem Park', 'Yes');\n",
      "INSERT INTO Customer VALUES (365390, 'Wilfred Joel', '632-327-2233', 'wjoel16@whitehouse.gov', '450 Beilfuss Junction', 'Yes');\n",
      "INSERT INTO Customer VALUES (872585, 'Karilynn Seymour', '207-292-0041', 'kseymour17@blogtalkradio.com', '2 East Parkway', 'Yes');\n",
      "INSERT INTO Customer VALUES (144402, 'Dasha Hiscoe', '262-608-3656', 'dhiscoe18@livejournal.com', '6 Northfield Drive', 'No');\n",
      "INSERT INTO Customer VALUES (345273, 'Josee Honeywood', '223-375-2439', 'jhoneywood19@engadget.com', '6048 Spaight Parkway', 'No');\n",
      "INSERT INTO Customer VALUES (415216, 'Nonnah Trass', '370-533-6961', 'ntrass1a@apache.org', '46327 Ludington Place', 'No');\n",
      "INSERT INTO Customer VALUES (733572, 'Dmitri Simmen', '228-899-5566', 'dsimmen1b@hibu.com', '505 Gateway Street', 'No');\n",
      "INSERT INTO Customer VALUES (74341, 'Cello Fassan', '467-460-7623', 'cfassan1c@google.com.br', '70873 Ludington Court', 'No');\n",
      "INSERT INTO Customer VALUES (249650, 'Curry Riggs', '895-961-5847', 'criggs1d@independent.co.uk', '3 Spenser Hill', 'No');\n"
     ]
    }
   ],
   "source": [
    "for Customer_id, Name, Phone, Email, Address, Driving_licence in customer.values.tolist():\n",
    "    print(\"INSERT INTO Customer VALUES ({}, '{}', '{}', '{}', '{}', '{}');\".format(Customer_id, Name, Phone, Email, Address, Driving_licence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0355fa4e-b93d-489d-ab1a-e594758e3d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Finance_details VALUES (224487837, 987673, '6247488842', 19114.12, 'Chase', 'Good');\n",
      "INSERT INTO Finance_details VALUES (477905881, 352841, '8017327721', 34847.84, 'Wells Fargo', 'Good');\n",
      "INSERT INTO Finance_details VALUES (331605414, 554593, '1463973416', 143162.64, 'Bank of America', 'Good');\n",
      "INSERT INTO Finance_details VALUES (180887800, 778711, '6120588712', 30689.89, 'Citigroup', 'Good');\n",
      "INSERT INTO Finance_details VALUES (853171579, 78932, '6663340180', 4148862.0, 'TD Bank', 'Good');\n",
      "INSERT INTO Finance_details VALUES (101113105, 319355, '1590610819', 35547.71, 'Chase', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (716354628, 719439, '7489280966', 73928.46, 'Wells Fargo', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (908690212, 538409, '3385123187', 131313.4, 'Bank of America', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (744117914, 979749, '7821448415', 34081.38, 'Citigroup', 'Good');\n",
      "INSERT INTO Finance_details VALUES (423776457, 640537, '4070604401', 114838.41, 'TD Bank', 'Good');\n",
      "INSERT INTO Finance_details VALUES (507344117, 871428, '1293729161', 31370.8, 'Chase', 'Good');\n",
      "INSERT INTO Finance_details VALUES (794174490, 847339, '1405124237', 33751.27, 'Wells Fargo', 'Good');\n",
      "INSERT INTO Finance_details VALUES (226770587, 94613, '3433461290', 88640.24, 'Bank of America', 'Good');\n",
      "INSERT INTO Finance_details VALUES (389894542, 628418, '8594077125', 54392.16, 'Citigroup', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (761113016, 974101, '4373764648', 8701.545, 'TD Bank', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (147766929, 930301, '5062457584', 25546.26, 'Chase', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (878906321, 915790, '2633498674', 31993.78, 'Wells Fargo', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (616368188, 389080, '2607184695', 92047.08, 'Bank of America', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (496445947, 336850, '4738448888', 92047.08, 'Citigroup', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (405467599, 176254, '5316421672', 32284.62, 'TD Bank', 'Good');\n",
      "INSERT INTO Finance_details VALUES (755180308, 638484, '5110480157', 97791.42, 'Chase', 'Good');\n",
      "INSERT INTO Finance_details VALUES (547237195, 621200, '8889194720', 19300.34, 'Wells Fargo', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (486071289, 555849, '8404188141', 19514.88, 'Bank of America', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (605639678, 972654, '3995617909', 10183.015, 'Citigroup', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (558251337, 492977, '2005036558', 10183.015, 'TD Bank', 'Good');\n",
      "INSERT INTO Finance_details VALUES (813918749, 77471, '6239350355', 106733.13, 'Chase', 'Good');\n",
      "INSERT INTO Finance_details VALUES (308388791, 289060, '8898570629', 12600.445, 'Wells Fargo', 'Good');\n",
      "INSERT INTO Finance_details VALUES (925441671, 166248, '4674612116', 57983.12, 'Bank of America', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (548039919, 830875, '3497327023', 20787.69, 'Citigroup', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (251770979, 591642, '9144957778', 34290.12, 'TD Bank', 'Bad');\n",
      "INSERT INTO Finance_details VALUES (898940497, 293654, '7482284503', 43070.24, 'Chase', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (992492793, 532909, '7884101536', 28572.39, 'Wells Fargo', 'Good');\n",
      "INSERT INTO Finance_details VALUES (352674436, 109075, '4450371309', 39641.54, 'Bank of America', 'Good');\n",
      "INSERT INTO Finance_details VALUES (204142702, 174408, '7788575072', 20186.02, 'Citigroup', 'Good');\n",
      "INSERT INTO Finance_details VALUES (755517133, 632251, '9174445104', 18627.64, 'TD Bank', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (837455178, 981115, '6144703129', 12986.745, 'Chase', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (074216507, 58082, '6668080649', 58317.0, 'Wells Fargo', 'Good');\n",
      "INSERT INTO Finance_details VALUES (772589547, 499661, '1702237609', 42171.98, 'Bank of America', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (835416871, 950610, '7899232129', 71681.4, 'Citigroup', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (330960638, 358893, '8296876239', 71681.4, 'TD Bank', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (397455329, 867938, '6898823636', 29469.98, 'Chase', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (212322085, 114971, '1631204329', 29469.98, 'Wells Fargo', 'Good');\n",
      "INSERT INTO Finance_details VALUES (087226137, 365390, '5461846948', 72559.36, 'Bank of America', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (062293192, 872585, '3442289093', 15566.02, 'Citigroup', 'Good');\n",
      "INSERT INTO Finance_details VALUES (727409990, 144402, '6158965543', 66567.32, 'TD Bank', 'Good');\n",
      "INSERT INTO Finance_details VALUES (016732103, 345273, '5264379216', 12909.895, 'Chase', 'Good');\n",
      "INSERT INTO Finance_details VALUES (198089791, 415216, '3321119986', 20601508.0, 'Wells Fargo', 'Good');\n",
      "INSERT INTO Finance_details VALUES (518012262, 733572, '3546730823', 30788.44, 'Bank of America', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (465939571, 74341, '2475885785', 30788.44, 'Citigroup', 'Standard');\n",
      "INSERT INTO Finance_details VALUES (860361556, 249650, '1238315826', 20574.47, 'TD Bank', 'Standard');\n"
     ]
    }
   ],
   "source": [
    "for Customer_id, SSN, Income,Credit_History,Account_number,Bank in finance.values.tolist():\n",
    "    print(\"INSERT INTO Finance_details VALUES ({}, {}, '{}', {}, '{}', '{}');\".format(SSN,Customer_id,Account_number,Income,Bank,Credit_History))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc383edf-7727-481b-971c-beb1b8addfe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Loan VALUES ('LP001015','Home',30,110000.0,987673);\n",
      "INSERT INTO Loan VALUES ('LP001022','Vehicle',30,126000.0,987673);\n",
      "INSERT INTO Loan VALUES ('LP001031','Home',30,208000.0,352841);\n",
      "INSERT INTO Loan VALUES ('LP001035','Home',30,100000.0,554593);\n",
      "INSERT INTO Loan VALUES ('LP001051','Home',30,78000.0,554593);\n",
      "INSERT INTO Loan VALUES ('LP001054','Home',30,152000.0,554593);\n",
      "INSERT INTO Loan VALUES ('LP001055','Home',30,59000.0,778711);\n",
      "INSERT INTO Loan VALUES ('LP001056','Vehicle',30,147000.0,78932);\n",
      "INSERT INTO Loan VALUES ('LP001059','Home',20,280000.0,319355);\n",
      "INSERT INTO Loan VALUES ('LP001067','Home',30,123000.0,719439);\n",
      "INSERT INTO Loan VALUES ('LP001078','Vehicle',30,90000.0,538409);\n",
      "INSERT INTO Loan VALUES ('LP001082','Home',30,162000.0,538409);\n",
      "INSERT INTO Loan VALUES ('LP001083','Home',15,40000.0,979749);\n",
      "INSERT INTO Loan VALUES ('LP001094','Vehicle',30,166000.0,979749);\n",
      "INSERT INTO Loan VALUES ('LP001096','Vehicle',30,124000.0,979749);\n",
      "INSERT INTO Loan VALUES ('LP001099','Vehicle',30,131000.0,640537);\n",
      "INSERT INTO Loan VALUES ('LP001105','Vehicle',30,200000.0,94613);\n",
      "INSERT INTO Loan VALUES ('LP001107','Vehicle',30,126000.0,628418);\n",
      "INSERT INTO Loan VALUES ('LP001108','Vehicle',30,300000.0,974101);\n",
      "INSERT INTO Loan VALUES ('LP001115','Vehicle',15,100000.0,930301);\n",
      "INSERT INTO Loan VALUES ('LP001121','Home',30,48000.0,176254);\n",
      "INSERT INTO Loan VALUES ('LP001124','Home',15,28000.0,176254);\n",
      "INSERT INTO Loan VALUES ('LP001128','Home',30,101000.0,176254);\n",
      "INSERT INTO Loan VALUES ('LP001135','Home',30,125000.0,555849);\n",
      "INSERT INTO Loan VALUES ('LP001149','Home',30,290000.0,555849);\n",
      "INSERT INTO Loan VALUES ('LP001153','Home',30,148000.0,289060);\n",
      "INSERT INTO Loan VALUES ('LP001163','Home',30,140000.0,166248);\n",
      "INSERT INTO Loan VALUES ('LP001169','Home',30,275000.0,830875);\n",
      "INSERT INTO Loan VALUES ('LP001174','Vehicle',30,57000.0,591642);\n",
      "INSERT INTO Loan VALUES ('LP001176','Vehicle',15,125000.0,293654);\n",
      "INSERT INTO Loan VALUES ('LP001177','Home',30,75000.0,58082);\n",
      "INSERT INTO Loan VALUES ('LP001183','Home',30,192000.0,58082);\n",
      "INSERT INTO Loan VALUES ('LP001185','Home',30,152000.0,950610);\n",
      "INSERT INTO Loan VALUES ('LP001187','Home',30,158000.0,358893);\n",
      "INSERT INTO Loan VALUES ('LP001190','Home',30,101000.0,114971);\n",
      "INSERT INTO Loan VALUES ('LP001203','Vehicle',30,176000.0,114971);\n",
      "INSERT INTO Loan VALUES ('LP001208','Vehicle',15,185000.0,114971);\n",
      "INSERT INTO Loan VALUES ('LP001210','Vehicle',30,90000.0,365390);\n",
      "INSERT INTO Loan VALUES ('LP001211','Vehicle',30,116000.0,872585);\n",
      "INSERT INTO Loan VALUES ('LP001219','Vehicle',30,138000.0,144402);\n",
      "INSERT INTO Loan VALUES ('LP001220','Home',30,100000.0,733572);\n",
      "INSERT INTO Loan VALUES ('LP001221','Home',30,110000.0,733572);\n",
      "INSERT INTO Loan VALUES ('LP001226','Home',30,90000.0,733572);\n",
      "INSERT INTO Loan VALUES ('LP001230','Home',30,200000.0,249650);\n",
      "INSERT INTO Loan VALUES ('LP001231','Home',30,84000.0,249650);\n",
      "INSERT INTO Loan VALUES ('LP001232','Home',0,185000.0,249650);\n",
      "INSERT INTO Loan VALUES ('LP001237','Home',30,162000.0,249650);\n",
      "INSERT INTO Loan VALUES ('LP001242','Home',30,108000.0,499661);\n",
      "INSERT INTO Loan VALUES ('LP001268','Home',0,187000.0,499661);\n",
      "INSERT INTO Loan VALUES ('LP001270','Home',30,187000.0,638484);\n",
      "INSERT INTO Loan VALUES ('LP001284','Home',30,124000.0,621200);\n",
      "INSERT INTO Loan VALUES ('LP001287','Home',30,120000.0,621200);\n",
      "INSERT INTO Loan VALUES ('LP001291','Home',30,160000.0,621200);\n",
      "INSERT INTO Loan VALUES ('LP001298','Home',15,30000.0,847339);\n",
      "INSERT INTO Loan VALUES ('LP001312','Vehicle',30,92000.0,847339);\n"
     ]
    }
   ],
   "source": [
    "for Loan_ID,LoanAmount,Customer_id,Tenure,LoanType in loan.values.tolist():\n",
    "    print(\"INSERT INTO Loan VALUES ('{}','{}',{},{},{});\".format(Loan_ID,LoanType,Tenure,LoanAmount,Customer_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985c970a-a4c5-4fa1-a404-2df440305cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('auto_policy_detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11449e58-4de0-45cb-a209-eeb7cee2b3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Policy_active_flag</th>\n",
       "      <th>Sum_assured</th>\n",
       "      <th>Tenure_in_months</th>\n",
       "      <th>Policy_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>Comprehensive Car Care</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>This policy covers all types of sedans and off...</td>\n",
       "      <td>Active</td>\n",
       "      <td>50000</td>\n",
       "      <td>12</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>Off-Road Adventure Shield</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Designed for SUVs and off-road vehicles, this ...</td>\n",
       "      <td>Active</td>\n",
       "      <td>70000</td>\n",
       "      <td>24</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>Oriental Motor Plan</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Tailored for motorcycles, this policy covers d...</td>\n",
       "      <td>Active</td>\n",
       "      <td>30000</td>\n",
       "      <td>12</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>Classic Car Elegance</td>\n",
       "      <td>Vintage Cars</td>\n",
       "      <td>Geared towards vintage and classic cars, this ...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>100000</td>\n",
       "      <td>60</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115</td>\n",
       "      <td>Electric Vehicle EcoShield</td>\n",
       "      <td>Electric Cars</td>\n",
       "      <td>Tailored for electric cars, this policy covers...</td>\n",
       "      <td>Active</td>\n",
       "      <td>60000</td>\n",
       "      <td>24</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Policy_id                        Name          Type   \\\n",
       "0        111      Comprehensive Car Care          Sedan   \n",
       "1        112   Off-Road Adventure Shield            SUV   \n",
       "2        113         Oriental Motor Plan      Motorbike   \n",
       "3        114        Classic Car Elegance   Vintage Cars   \n",
       "4        115  Electric Vehicle EcoShield  Electric Cars   \n",
       "\n",
       "                                         Description Policy_active_flag  \\\n",
       "0  This policy covers all types of sedans and off...             Active   \n",
       "1  Designed for SUVs and off-road vehicles, this ...             Active   \n",
       "2  Tailored for motorcycles, this policy covers d...             Active   \n",
       "3  Geared towards vintage and classic cars, this ...           Inactive   \n",
       "4  Tailored for electric cars, this policy covers...             Active   \n",
       "\n",
       "   Sum_assured    Tenure_in_months   Policy_type  \n",
       "0        50000                  12          Auto  \n",
       "1        70000                  24          Auto  \n",
       "2        30000                  12          Auto  \n",
       "3       100000                  60          Auto  \n",
       "4        60000                  24          Auto  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d3a2e19-6a7a-4f90-8869-fe16f1417dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO AutoPolicy_detail VALUES (111,'Comprehensive Car Care','Sedan','This policy covers all types of sedans and offers comprehensive protection, including coverage for accidents, theft, natural disasters, and medical expenses.','Active',50000,12,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (112,'Off-Road Adventure Shield','SUV','Designed for SUVs and off-road vehicles, this policy provides specialized coverage for damages incurred during off-road adventures, including collisions, rollovers, and towing expenses.','Active',70000,24,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (113,'Oriental Motor Plan','Motorbike','Tailored for motorcycles, this policy covers damages resulting from accidents, theft, and third-party liabilities, ensuring the freedom of the open road with peace of mind.','Active',30000,12,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (114,'Classic Car Elegance','Vintage Cars','Geared towards vintage and classic cars, this policy offers extensive coverage for restoration costs, market value, and special roadside assistance, preserving the elegance of your cherished automobile.','Inactive',100000,60,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (115,'Electric Vehicle EcoShield','Electric Cars','Tailored for electric cars, this policy covers battery damage, charging equipment, and specialized repairs, promoting eco-friendly driving with dedicated insurance support.','Active',60000,24,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (116,'Family safety plan','Sedan','This policy emphasizes safety, covering child seat replacements, medical expenses for passengers, and roadside assistance for families on the go.','Active',50000,12,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (117,'Luxury Sedan Prestige Coverage','Sedan','Catering to luxury sedans, this policy offers specialized coverage for high-end interiors, technology systems, and concierge services, ensuring that every aspect of your luxury driving experience is protected','Active',100000,24,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (118,'SafeDrive','Motorbike','Premium policy offering high coverage limits, including coverage for uninsured motorists and roadside assistance.','Active',100000,24,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (119,'Guardian Auto Insurance','Electric Cars','Short-term policy with comprehensive coverage, ideal for temporary needs such as rental cars or seasonal driving.','Inactive',60000,12,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (120,'DriveSure Insuranc','SUV','Policy tailored for frequent travelers, offering coverage for rental cars and drivers in multiple states.','Active',80000,12,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (121,'Liberty Auto Assurance','Sedan & SUV','Standard coverage for collisions and comprehensive damages, with optional add-ons for enhanced protection.','Active',50000,12,'Auto');\n",
      "INSERT INTO AutoPolicy_detail VALUES (122,'ABC Plan','Sedan & SUV','Basic coverage for liability and medical expenses, suitable for low-risk drivers.','Inactive',40000,12,'Auto');\n"
     ]
    }
   ],
   "source": [
    "for Policy_id, Name, Type,Description,Policy_active_flag, Sum_assured, Tenure_in_months, Policy_type in auto.values.tolist():\n",
    "    print(\"INSERT INTO AutoPolicy_detail VALUES ({},'{}','{}','{}','{}',{},{},'{}');\".format(Policy_id, Name, Type,Description,Policy_active_flag, Sum_assured, Tenure_in_months, Policy_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b4586a5-23a5-48ab-861a-990ff954e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = pd.read_csv('home.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22fbf9a0-cf41-43fe-9755-99c209242908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Policy_active_flag</th>\n",
       "      <th>Sum_assured</th>\n",
       "      <th>Tenure_in_months</th>\n",
       "      <th>Policy_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>HomeShield</td>\n",
       "      <td>Rent and Owned</td>\n",
       "      <td>Comprehensive coverage for the structure of th...</td>\n",
       "      <td>Active</td>\n",
       "      <td>300000</td>\n",
       "      <td>12</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>SecureHome</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Premium policy offering high coverage limits, ...</td>\n",
       "      <td>Active</td>\n",
       "      <td>500000</td>\n",
       "      <td>24</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>SafeHaven Insurance</td>\n",
       "      <td>Rent and Owned</td>\n",
       "      <td>Basic coverage for the home's structure and es...</td>\n",
       "      <td>Active</td>\n",
       "      <td>250000</td>\n",
       "      <td>12</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>Liberty Home Protection</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Standard policy covering damages from fire, va...</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>400000</td>\n",
       "      <td>12</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>EverGuard Home Insurance</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Long-term coverage with benefits like extended...</td>\n",
       "      <td>Active</td>\n",
       "      <td>350000</td>\n",
       "      <td>36</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Policy_id                      Name           Type   \\\n",
       "0        100                HomeShield  Rent and Owned   \n",
       "1        101                SecureHome           Owned   \n",
       "2        102       SafeHaven Insurance  Rent and Owned   \n",
       "3        103   Liberty Home Protection           Owned   \n",
       "4        104  EverGuard Home Insurance           Owned   \n",
       "\n",
       "                                         Description Policy_active_flag  \\\n",
       "0  Comprehensive coverage for the structure of th...             Active   \n",
       "1  Premium policy offering high coverage limits, ...             Active   \n",
       "2  Basic coverage for the home's structure and es...             Active   \n",
       "3  Standard policy covering damages from fire, va...           Inactive   \n",
       "4  Long-term coverage with benefits like extended...             Active   \n",
       "\n",
       "   Sum_assured    Tenure_in_months   Policy_type  \n",
       "0       300000                  12          Home  \n",
       "1       500000                  24          Home  \n",
       "2       250000                  12          Home  \n",
       "3       400000                  12          Home  \n",
       "4       350000                  36          Home  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd618123-3fcd-49ad-a729-5ef7142e5363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO HomePolicy_detail VALUES (100,'HomeShield','Rent and Owned','Comprehensive coverage for the structure of the home, personal belongings, liability protection, and additional living expenses in case of temporary displacement due to covered events.','Active',300000,12,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (101,'SecureHome','Owned','Premium policy offering high coverage limits, including protection against natural disasters, theft, and personal injury liability, with options for custom add-ons.','Active',500000,24,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (102,'SafeHaven Insurance','Rent and Owned','Basic coverage for the home's structure and essential belongings, suitable for homeowners seeking affordable protection against common risks.','Active',250000,12,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (103,'Liberty Home Protection','Owned','Standard policy covering damages from fire, vandalism, and certain natural disasters, along with liability coverage for accidents on the property.','Inactive',400000,12,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (104,'EverGuard Home Insurance','Owned','Long-term coverage with benefits like extended replacement cost, which ensures the home can be rebuilt to its original condition even if construction costs rise.','Active',350000,36,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (105,'Guardian Home Assurance','Rent and Owned','Policy offering protection against various perils, including water damage, mold, and coverage for high-value items like jewelry and artwork.','Active',200000,12,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (106,'National Home Protection','Rent','Short-term policy ideal for renters, offering coverage for personal belongings, liability, and temporary living expenses in case of covered events.','Active',100000,24,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (107,'Reliable Home Insurance','Owned','Policy tailored for homeowners with additional structures on their property, such as detached garages or sheds, providing coverage for both the main home and other structures.','Active',100000,24,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (108,'SmartGuard Home Insurance','Owned','Customizable policy allowing homeowners to choose specific coverage limits and endorsements to protect unique assets and accommodate individual needs.','Inactive',350000,12,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (109,'SafeHome Solutions','Owned','High-value policy with features like identity theft protection, credit card coverage, and coverage for unauthorized transactions due to cybercrime.','Active',555000,12,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (110,'HomeAssure Services','Rent','Policy offering coverage for home systems and appliances, such as HVAC, electrical, and plumbing, providing financial protection against unexpected repair or replacement costs.','Active',400000,12,'Home');\n",
      "INSERT INTO HomePolicy_detail VALUES (111,'One Home Insurance','Owned','Long-term policy with perks like extended coverage for valuables, home office equipment, and reimbursement for temporary housing and meals during repairs.','Inactive',250000,12,'Home');\n"
     ]
    }
   ],
   "source": [
    "for Policy_id, Name, Type,Description,Policy_active_flag, Sum_assured, Tenure_in_months, Policy_type in home.values.tolist():\n",
    "    print(\"INSERT INTO HomePolicy_detail VALUES ({},'{}','{}','{}','{}',{},{},'{}');\".format(Policy_id, Name, Type,Description,Policy_active_flag, Sum_assured, Tenure_in_months, Policy_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82d19596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Holder_id  Customer_id  Home_Policy_id  Auto_Policy_id status_of_policy  \\\n",
      "0           1       176254               0             119           Active   \n",
      "1           2       628418             104             116         Inactive   \n",
      "2           3       538409             100             114           Active   \n",
      "3           4       638484             103             117           Active   \n",
      "4           5       554593             109             119         Inactive   \n",
      "5           6       640537             100             119           Active   \n",
      "6           7       176254             111             122         Inactive   \n",
      "7           8       114971             109             112           Active   \n",
      "8           9       930301             109               0           Active   \n",
      "9          10       981115             108             112         Inactive   \n",
      "10         11       499661             102             119         Inactive   \n",
      "11         12       293654             111             116         Inactive   \n",
      "12         13       499661             106             118           Active   \n",
      "13         14       389080             103             117         Inactive   \n",
      "14         15       415216             104             116           Active   \n",
      "15         16       293654             110             119           Active   \n",
      "16         17       319355             103             116           Active   \n",
      "17         18       847339             110             119         Inactive   \n",
      "18         19       365390             107               0         Inactive   \n",
      "19         20       555849             102               0         Inactive   \n",
      "20         21       638484             111             120           Active   \n",
      "21         22       114971             111             117           Active   \n",
      "22         23       981115             103             122         Inactive   \n",
      "23         24       176254             103               0         Inactive   \n",
      "24         25       930301             111             121         Inactive   \n",
      "25         26       249650             104             117           Active   \n",
      "26         27       974101             100             117         Inactive   \n",
      "27         28        74341             104             114         Inactive   \n",
      "28         29       979749             101             113           Active   \n",
      "29         30       365390             102             122           Active   \n",
      "30         31        94613             100               0         Inactive   \n",
      "31         32       979749               0             119           Active   \n",
      "32         33       345273             107             118         Inactive   \n",
      "33         34       979749             105             113           Active   \n",
      "34         35       972654             110             122           Active   \n",
      "35         36       621200             103             113         Inactive   \n",
      "36         37       632251             102             113           Active   \n",
      "37         38       492977             108             118           Active   \n",
      "38         39        77471             103             114         Inactive   \n",
      "39         40       628418             108             114         Inactive   \n",
      "40         41       640537             101             119           Active   \n",
      "41         42        58082             109             112           Active   \n",
      "42         43       352841             105             117         Inactive   \n",
      "43         44       974101             101               0         Inactive   \n",
      "44         45        94613             103               0           Active   \n",
      "45         46       176254             102             119           Active   \n",
      "46         47       591642             101             119         Inactive   \n",
      "47         48       830875               0             111           Active   \n",
      "48         49       628418             101             122         Inactive   \n",
      "49         50       319355             101             118           Active   \n",
      "\n",
      "    StartDate ExpiryDate  RenewDate at_risk_flag  Agent_id  \n",
      "0  2022-06-07 2022-08-16 2023-05-19           No     54342  \n",
      "1  2022-02-08 2022-10-27 2023-01-28           No     46129  \n",
      "2  2022-03-29 2022-09-22 2023-01-20          Yes     96845  \n",
      "3  2022-05-02 2022-10-07 2023-01-25          Yes     47781  \n",
      "4  2022-02-06 2022-08-15 2023-03-07          Yes      4629  \n",
      "5  2022-01-06 2022-11-19 2023-02-04          Yes     39992  \n",
      "6  2022-05-25 2022-07-19 2023-06-13          Yes     24998  \n",
      "7  2022-06-30 2022-08-29 2023-02-04          Yes     58102  \n",
      "8  2022-02-20 2022-08-19 2023-02-19          Yes     92900  \n",
      "9  2022-03-19 2022-12-10 2023-06-21           No     52121  \n",
      "10 2022-02-26 2022-09-13 2023-06-07           No     62599  \n",
      "11 2022-03-26 2022-08-15 2023-04-07          Yes     24998  \n",
      "12 2022-01-27 2022-11-19 2023-04-06           No     96845  \n",
      "13 2022-03-13 2022-12-01 2023-03-04           No     38302  \n",
      "14 2022-02-13 2022-08-16 2023-03-23          Yes     74988  \n",
      "15 2022-01-23 2022-12-12 2023-01-12          Yes     80340  \n",
      "16 2022-06-23 2022-11-16 2023-05-12          Yes     96845  \n",
      "17 2022-04-03 2022-08-02 2023-01-28          Yes       125  \n",
      "18 2022-05-26 2022-08-09 2023-01-17          Yes     56777  \n",
      "19 2022-02-02 2022-10-01 2023-01-22           No     33645  \n",
      "20 2022-04-27 2022-10-08 2023-04-21           No     47781  \n",
      "21 2022-02-28 2022-07-18 2023-05-22          Yes     88459  \n",
      "22 2022-03-03 2022-08-21 2023-05-03          Yes     88459  \n",
      "23 2022-02-19 2022-12-05 2023-01-02           No     66624  \n",
      "24 2022-04-07 2022-11-05 2023-03-16           No     62068  \n",
      "25 2022-05-17 2022-09-18 2023-04-12          Yes     27853  \n",
      "26 2022-05-26 2022-07-13 2023-05-16          Yes     92786  \n",
      "27 2022-03-21 2022-11-10 2023-02-05           No     52121  \n",
      "28 2022-05-08 2022-09-04 2023-01-05          Yes     31487  \n",
      "29 2022-02-24 2022-10-22 2023-04-16          Yes     95587  \n",
      "30 2022-06-16 2022-11-15 2023-03-25          Yes     33645  \n",
      "31 2022-02-01 2022-11-06 2023-01-15           No     31957  \n",
      "32 2022-06-21 2022-12-14 2023-05-15          Yes     47590  \n",
      "33 2022-04-13 2022-11-02 2023-01-08          Yes     66624  \n",
      "34 2022-02-23 2022-10-04 2023-04-11          Yes     11119  \n",
      "35 2022-05-21 2022-08-29 2023-01-29          Yes       125  \n",
      "36 2022-01-13 2022-10-13 2023-04-18          Yes     74988  \n",
      "37 2022-05-15 2022-08-04 2023-03-31           No     85484  \n",
      "38 2022-03-18 2022-12-16 2023-05-16           No     31487  \n",
      "39 2022-05-18 2022-10-11 2023-02-27          Yes     76607  \n",
      "40 2022-05-11 2022-11-19 2023-05-18          Yes     97444  \n",
      "41 2022-06-02 2022-11-26 2023-01-02          Yes     74988  \n",
      "42 2022-06-28 2022-12-22 2023-01-29           No     52121  \n",
      "43 2022-03-16 2022-10-10 2023-02-10           No     95587  \n",
      "44 2022-03-31 2022-12-08 2023-03-23           No     97840  \n",
      "45 2022-06-25 2022-10-30 2023-03-23           No     68833  \n",
      "46 2022-06-27 2022-07-19 2023-05-11          Yes     71268  \n",
      "47 2022-03-13 2022-11-12 2023-04-07           No     16339  \n",
      "48 2022-02-04 2022-07-02 2023-03-26          Yes     80340  \n",
      "49 2022-02-11 2022-09-12 2023-01-13           No     31957  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to generate random dates within a given range\n",
    "def random_dates(start_date, end_date, n=10):\n",
    "    date_range = [start_date + timedelta(days=random.randint(0, (end_date - start_date).days)) for _ in range(n)]\n",
    "    return date_range\n",
    "\n",
    "# Sample data for Policy_Holder\n",
    "customer_ids = [987673, 352841, 554593, 778711, 78932, 319355, 719439, 538409, 979749, 640537,\n",
    "                871428, 847339, 94613, 628418, 974101, 930301, 915790, 389080, 336850, 176254,\n",
    "                638484, 621200, 555849, 972654, 492977, 77471, 289060, 166248, 830875, 591642,\n",
    "                293654, 532909, 109075, 174408, 632251, 981115, 58082, 499661, 950610, 358893,\n",
    "                867938, 114971, 365390, 872585, 144402, 345273, 415216, 733572, 74341, 249650]\n",
    "\n",
    "auto_policy_ids = list(range(111, 123))\n",
    "home_policy_ids = list(range(100, 112))\n",
    "agent_ids = [97444, 80340, 6768, 52121, 85926, 73812, 95189, 92085, 92900, 69259,\n",
    "             13041, 78600, 33645, 47590, 54342, 74988, 39178, 30720, 4629, 96845,\n",
    "             66218, 97840, 35917, 49539, 80633, 92786, 68833, 71268, 80048, 31957,\n",
    "             88459, 58102, 125, 56777, 11119, 66624, 95587, 46129, 62599, 38302,\n",
    "             62068, 76607, 2340, 85484, 27853, 16339, 24998, 47781, 39992, 31487]\n",
    "\n",
    "# Create a DataFrame for Policy_Holder\n",
    "home_policy_ids = random.choices(home_policy_ids + [0], k=50)\n",
    "auto_policy_ids = random.choices(auto_policy_ids + [0], k=50)\n",
    "# policy_ids = [auto_policy_ids[i] if auto_policy_ids[i] != 0 else home_policy_ids[i] for i in range(50)]\n",
    "\n",
    "data = {\n",
    "    'Holder_id': list(range(1, 51)),\n",
    "    'Customer_id': random.choices(customer_ids, k=50),\n",
    "    'Home_Policy_id': home_policy_ids,\n",
    "    'Auto_Policy_id': auto_policy_ids,\n",
    "    #'Policy_type': ['Auto' if auto_policy_ids[i] != 0 else 'Home' if home_policy_ids[i] != 0 else 'Both' if auto_policy_ids[i] != 0 and home_policy_ids[i] != 0 else None for i in range(50)],\n",
    "    'status_of_policy': random.choices(['Active', 'Inactive'], k=50),\n",
    "    'StartDate': random_dates(datetime(2022, 1, 1), datetime(2022, 6, 30), n=50),\n",
    "    'ExpiryDate': random_dates(datetime(2022, 7, 1), datetime(2022, 12, 31), n=50),\n",
    "    'RenewDate': random_dates(datetime(2023, 1, 1), datetime(2023, 6, 30), n=50),\n",
    "    'at_risk_flag': random.choices(['Yes', 'No'], k=50),\n",
    "    'Agent_id': random.choices(agent_ids, k=50)\n",
    "}\n",
    "\n",
    "policy_holder_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(policy_holder_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "policy_holder_df.to_csv('policy_holder_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3ede8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Policy_Holder VALUES (1,176254,0,119,'Active','2022-06-07 00:00:00','2022-08-16 00:00:00', '2023-05-19 00:00:00','No',54342);\n",
      "INSERT INTO Policy_Holder VALUES (2,628418,104,116,'Inactive','2022-02-08 00:00:00','2022-10-27 00:00:00', '2023-01-28 00:00:00','No',46129);\n",
      "INSERT INTO Policy_Holder VALUES (3,538409,100,114,'Active','2022-03-29 00:00:00','2022-09-22 00:00:00', '2023-01-20 00:00:00','Yes',96845);\n",
      "INSERT INTO Policy_Holder VALUES (4,638484,103,117,'Active','2022-05-02 00:00:00','2022-10-07 00:00:00', '2023-01-25 00:00:00','Yes',47781);\n",
      "INSERT INTO Policy_Holder VALUES (5,554593,109,119,'Inactive','2022-02-06 00:00:00','2022-08-15 00:00:00', '2023-03-07 00:00:00','Yes',4629);\n",
      "INSERT INTO Policy_Holder VALUES (6,640537,100,119,'Active','2022-01-06 00:00:00','2022-11-19 00:00:00', '2023-02-04 00:00:00','Yes',39992);\n",
      "INSERT INTO Policy_Holder VALUES (7,176254,111,122,'Inactive','2022-05-25 00:00:00','2022-07-19 00:00:00', '2023-06-13 00:00:00','Yes',24998);\n",
      "INSERT INTO Policy_Holder VALUES (8,114971,109,112,'Active','2022-06-30 00:00:00','2022-08-29 00:00:00', '2023-02-04 00:00:00','Yes',58102);\n",
      "INSERT INTO Policy_Holder VALUES (9,930301,109,0,'Active','2022-02-20 00:00:00','2022-08-19 00:00:00', '2023-02-19 00:00:00','Yes',92900);\n",
      "INSERT INTO Policy_Holder VALUES (10,981115,108,112,'Inactive','2022-03-19 00:00:00','2022-12-10 00:00:00', '2023-06-21 00:00:00','No',52121);\n",
      "INSERT INTO Policy_Holder VALUES (11,499661,102,119,'Inactive','2022-02-26 00:00:00','2022-09-13 00:00:00', '2023-06-07 00:00:00','No',62599);\n",
      "INSERT INTO Policy_Holder VALUES (12,293654,111,116,'Inactive','2022-03-26 00:00:00','2022-08-15 00:00:00', '2023-04-07 00:00:00','Yes',24998);\n",
      "INSERT INTO Policy_Holder VALUES (13,499661,106,118,'Active','2022-01-27 00:00:00','2022-11-19 00:00:00', '2023-04-06 00:00:00','No',96845);\n",
      "INSERT INTO Policy_Holder VALUES (14,389080,103,117,'Inactive','2022-03-13 00:00:00','2022-12-01 00:00:00', '2023-03-04 00:00:00','No',38302);\n",
      "INSERT INTO Policy_Holder VALUES (15,415216,104,116,'Active','2022-02-13 00:00:00','2022-08-16 00:00:00', '2023-03-23 00:00:00','Yes',74988);\n",
      "INSERT INTO Policy_Holder VALUES (16,293654,110,119,'Active','2022-01-23 00:00:00','2022-12-12 00:00:00', '2023-01-12 00:00:00','Yes',80340);\n",
      "INSERT INTO Policy_Holder VALUES (17,319355,103,116,'Active','2022-06-23 00:00:00','2022-11-16 00:00:00', '2023-05-12 00:00:00','Yes',96845);\n",
      "INSERT INTO Policy_Holder VALUES (18,847339,110,119,'Inactive','2022-04-03 00:00:00','2022-08-02 00:00:00', '2023-01-28 00:00:00','Yes',125);\n",
      "INSERT INTO Policy_Holder VALUES (19,365390,107,0,'Inactive','2022-05-26 00:00:00','2022-08-09 00:00:00', '2023-01-17 00:00:00','Yes',56777);\n",
      "INSERT INTO Policy_Holder VALUES (20,555849,102,0,'Inactive','2022-02-02 00:00:00','2022-10-01 00:00:00', '2023-01-22 00:00:00','No',33645);\n",
      "INSERT INTO Policy_Holder VALUES (21,638484,111,120,'Active','2022-04-27 00:00:00','2022-10-08 00:00:00', '2023-04-21 00:00:00','No',47781);\n",
      "INSERT INTO Policy_Holder VALUES (22,114971,111,117,'Active','2022-02-28 00:00:00','2022-07-18 00:00:00', '2023-05-22 00:00:00','Yes',88459);\n",
      "INSERT INTO Policy_Holder VALUES (23,981115,103,122,'Inactive','2022-03-03 00:00:00','2022-08-21 00:00:00', '2023-05-03 00:00:00','Yes',88459);\n",
      "INSERT INTO Policy_Holder VALUES (24,176254,103,0,'Inactive','2022-02-19 00:00:00','2022-12-05 00:00:00', '2023-01-02 00:00:00','No',66624);\n",
      "INSERT INTO Policy_Holder VALUES (25,930301,111,121,'Inactive','2022-04-07 00:00:00','2022-11-05 00:00:00', '2023-03-16 00:00:00','No',62068);\n",
      "INSERT INTO Policy_Holder VALUES (26,249650,104,117,'Active','2022-05-17 00:00:00','2022-09-18 00:00:00', '2023-04-12 00:00:00','Yes',27853);\n",
      "INSERT INTO Policy_Holder VALUES (27,974101,100,117,'Inactive','2022-05-26 00:00:00','2022-07-13 00:00:00', '2023-05-16 00:00:00','Yes',92786);\n",
      "INSERT INTO Policy_Holder VALUES (28,74341,104,114,'Inactive','2022-03-21 00:00:00','2022-11-10 00:00:00', '2023-02-05 00:00:00','No',52121);\n",
      "INSERT INTO Policy_Holder VALUES (29,979749,101,113,'Active','2022-05-08 00:00:00','2022-09-04 00:00:00', '2023-01-05 00:00:00','Yes',31487);\n",
      "INSERT INTO Policy_Holder VALUES (30,365390,102,122,'Active','2022-02-24 00:00:00','2022-10-22 00:00:00', '2023-04-16 00:00:00','Yes',95587);\n",
      "INSERT INTO Policy_Holder VALUES (31,94613,100,0,'Inactive','2022-06-16 00:00:00','2022-11-15 00:00:00', '2023-03-25 00:00:00','Yes',33645);\n",
      "INSERT INTO Policy_Holder VALUES (32,979749,0,119,'Active','2022-02-01 00:00:00','2022-11-06 00:00:00', '2023-01-15 00:00:00','No',31957);\n",
      "INSERT INTO Policy_Holder VALUES (33,345273,107,118,'Inactive','2022-06-21 00:00:00','2022-12-14 00:00:00', '2023-05-15 00:00:00','Yes',47590);\n",
      "INSERT INTO Policy_Holder VALUES (34,979749,105,113,'Active','2022-04-13 00:00:00','2022-11-02 00:00:00', '2023-01-08 00:00:00','Yes',66624);\n",
      "INSERT INTO Policy_Holder VALUES (35,972654,110,122,'Active','2022-02-23 00:00:00','2022-10-04 00:00:00', '2023-04-11 00:00:00','Yes',11119);\n",
      "INSERT INTO Policy_Holder VALUES (36,621200,103,113,'Inactive','2022-05-21 00:00:00','2022-08-29 00:00:00', '2023-01-29 00:00:00','Yes',125);\n",
      "INSERT INTO Policy_Holder VALUES (37,632251,102,113,'Active','2022-01-13 00:00:00','2022-10-13 00:00:00', '2023-04-18 00:00:00','Yes',74988);\n",
      "INSERT INTO Policy_Holder VALUES (38,492977,108,118,'Active','2022-05-15 00:00:00','2022-08-04 00:00:00', '2023-03-31 00:00:00','No',85484);\n",
      "INSERT INTO Policy_Holder VALUES (39,77471,103,114,'Inactive','2022-03-18 00:00:00','2022-12-16 00:00:00', '2023-05-16 00:00:00','No',31487);\n",
      "INSERT INTO Policy_Holder VALUES (40,628418,108,114,'Inactive','2022-05-18 00:00:00','2022-10-11 00:00:00', '2023-02-27 00:00:00','Yes',76607);\n",
      "INSERT INTO Policy_Holder VALUES (41,640537,101,119,'Active','2022-05-11 00:00:00','2022-11-19 00:00:00', '2023-05-18 00:00:00','Yes',97444);\n",
      "INSERT INTO Policy_Holder VALUES (42,58082,109,112,'Active','2022-06-02 00:00:00','2022-11-26 00:00:00', '2023-01-02 00:00:00','Yes',74988);\n",
      "INSERT INTO Policy_Holder VALUES (43,352841,105,117,'Inactive','2022-06-28 00:00:00','2022-12-22 00:00:00', '2023-01-29 00:00:00','No',52121);\n",
      "INSERT INTO Policy_Holder VALUES (44,974101,101,0,'Inactive','2022-03-16 00:00:00','2022-10-10 00:00:00', '2023-02-10 00:00:00','No',95587);\n",
      "INSERT INTO Policy_Holder VALUES (45,94613,103,0,'Active','2022-03-31 00:00:00','2022-12-08 00:00:00', '2023-03-23 00:00:00','No',97840);\n",
      "INSERT INTO Policy_Holder VALUES (46,176254,102,119,'Active','2022-06-25 00:00:00','2022-10-30 00:00:00', '2023-03-23 00:00:00','No',68833);\n",
      "INSERT INTO Policy_Holder VALUES (47,591642,101,119,'Inactive','2022-06-27 00:00:00','2022-07-19 00:00:00', '2023-05-11 00:00:00','Yes',71268);\n",
      "INSERT INTO Policy_Holder VALUES (48,830875,0,111,'Active','2022-03-13 00:00:00','2022-11-12 00:00:00', '2023-04-07 00:00:00','No',16339);\n",
      "INSERT INTO Policy_Holder VALUES (49,628418,101,122,'Inactive','2022-02-04 00:00:00','2022-07-02 00:00:00', '2023-03-26 00:00:00','Yes',80340);\n",
      "INSERT INTO Policy_Holder VALUES (50,319355,101,118,'Active','2022-02-11 00:00:00','2022-09-12 00:00:00', '2023-01-13 00:00:00','No',31957);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Policy_holder table\n",
    "for Holder_id, Customer_id, Home_Policy_id, Auto_Policy_id, status_of_policy, Start_Date, ExpiryDate, RenewDate, at_risk_flag, Agent_id in policy_holder_df.values.tolist():\n",
    "    print(\"INSERT INTO Policy_Holder VALUES ({},{},{},{},'{}','{}','{}', '{}','{}',{});\".format(Holder_id, Customer_id, Home_Policy_id, Auto_Policy_id, status_of_policy, Start_Date, ExpiryDate, RenewDate, at_risk_flag, Agent_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "645ad342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-20.0.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /Users/karanbadlani/anaconda3/lib/python3.11/site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/karanbadlani/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-20.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a9aabc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Report_id        Date  Damage_amount\n",
      "0           1  2023-04-11           4900\n",
      "1           2  2023-10-12           4034\n",
      "2           3  2023-07-30           4697\n",
      "3           4  2023-06-03           3866\n",
      "4           5  2022-11-12           8843\n",
      "5           6  2023-03-30           5203\n",
      "6           7  2023-06-20           3597\n",
      "7           8  2023-09-06           7932\n",
      "8           9  2023-03-07           9240\n",
      "9          10  2023-03-12           8678\n",
      "10         11  2023-04-02           2970\n",
      "11         12  2023-08-18           5651\n",
      "12         13  2023-01-10           2433\n",
      "13         14  2023-02-01           7481\n",
      "14         15  2023-10-13           9606\n",
      "15         16  2023-01-02           4016\n",
      "16         17  2023-03-25           3825\n",
      "17         18  2022-12-15           5752\n",
      "18         19  2023-05-10           1536\n",
      "19         20  2023-09-18           2185\n",
      "20         21  2023-08-19           4878\n",
      "21         22  2023-09-09           7132\n",
      "22         23  2023-09-29           7753\n",
      "23         24  2023-06-07           9326\n",
      "24         25  2022-12-26           5812\n",
      "25         26  2023-01-18           7734\n",
      "26         27  2023-08-04           6483\n",
      "27         28  2023-08-26           3024\n",
      "28         29  2023-06-27           2968\n",
      "29         30  2023-03-08           8971\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Generate data for Report_Details\n",
    "data = {\n",
    "    'Report_id': list(range(1, 31)),\n",
    "    'Date': [fake.date_between(start_date='-365d', end_date='today') for _ in range(30)],\n",
    "    'Damage_amount': [random.randint(100, 10000) for _ in range(30)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "report_details_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(report_details_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "report_details_df.to_csv('report_details_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea1a676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Report_Details VALUES (1,'2023-04-11',4900);\n",
      "INSERT INTO Report_Details VALUES (2,'2023-10-12',4034);\n",
      "INSERT INTO Report_Details VALUES (3,'2023-07-30',4697);\n",
      "INSERT INTO Report_Details VALUES (4,'2023-06-03',3866);\n",
      "INSERT INTO Report_Details VALUES (5,'2022-11-12',8843);\n",
      "INSERT INTO Report_Details VALUES (6,'2023-03-30',5203);\n",
      "INSERT INTO Report_Details VALUES (7,'2023-06-20',3597);\n",
      "INSERT INTO Report_Details VALUES (8,'2023-09-06',7932);\n",
      "INSERT INTO Report_Details VALUES (9,'2023-03-07',9240);\n",
      "INSERT INTO Report_Details VALUES (10,'2023-03-12',8678);\n",
      "INSERT INTO Report_Details VALUES (11,'2023-04-02',2970);\n",
      "INSERT INTO Report_Details VALUES (12,'2023-08-18',5651);\n",
      "INSERT INTO Report_Details VALUES (13,'2023-01-10',2433);\n",
      "INSERT INTO Report_Details VALUES (14,'2023-02-01',7481);\n",
      "INSERT INTO Report_Details VALUES (15,'2023-10-13',9606);\n",
      "INSERT INTO Report_Details VALUES (16,'2023-01-02',4016);\n",
      "INSERT INTO Report_Details VALUES (17,'2023-03-25',3825);\n",
      "INSERT INTO Report_Details VALUES (18,'2022-12-15',5752);\n",
      "INSERT INTO Report_Details VALUES (19,'2023-05-10',1536);\n",
      "INSERT INTO Report_Details VALUES (20,'2023-09-18',2185);\n",
      "INSERT INTO Report_Details VALUES (21,'2023-08-19',4878);\n",
      "INSERT INTO Report_Details VALUES (22,'2023-09-09',7132);\n",
      "INSERT INTO Report_Details VALUES (23,'2023-09-29',7753);\n",
      "INSERT INTO Report_Details VALUES (24,'2023-06-07',9326);\n",
      "INSERT INTO Report_Details VALUES (25,'2022-12-26',5812);\n",
      "INSERT INTO Report_Details VALUES (26,'2023-01-18',7734);\n",
      "INSERT INTO Report_Details VALUES (27,'2023-08-04',6483);\n",
      "INSERT INTO Report_Details VALUES (28,'2023-08-26',3024);\n",
      "INSERT INTO Report_Details VALUES (29,'2023-06-27',2968);\n",
      "INSERT INTO Report_Details VALUES (30,'2023-03-08',8971);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Report_Details table\n",
    "for Report_id, Date, Damage_amount  in report_details_df.values.tolist():\n",
    "    print(\"INSERT INTO Report_Details VALUES ({},'{}',{});\".format(Report_id, Date, Damage_amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9c0187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'vehicle_details.csv'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "holder_ids = list(range(1, 51))\n",
    "loan_ids = ['LP001015', 'LP001022', 'LP001031', 'LP001035', 'LP001051', 'LP001054', 'LP001055', 'LP001056', 'LP001059',\n",
    "            'LP001067', 'LP001078', 'LP001082', 'LP001083', 'LP001094', 'LP001096', 'LP001099', 'LP001105', 'LP001107',\n",
    "            'LP001108', 'LP001115', 'LP001121', 'LP001124', 'LP001128', 'LP001135', 'LP001149', 'LP001153', 'LP001163',\n",
    "            'LP001169', 'LP001174', 'LP001176', 'LP001177', 'LP001183', 'LP001185', 'LP001187', 'LP001190', 'LP001203',\n",
    "            'LP001208', 'LP001210', 'LP001211', 'LP001219', 'LP001220', 'LP001221', 'LP001226', 'LP001230', 'LP001231',\n",
    "            'LP001232', 'LP001237', 'LP001242', 'LP001268', 'LP001270', 'LP001284', 'LP001287', 'LP001291', 'LP001298',\n",
    "            'LP001312']\n",
    "manufacturers = ['Honda', 'BMW', 'Audi', 'Mercedes', 'Mazda', 'Lamborghini', 'Mustang', 'Kia', 'Maruti', 'Lincoln', 'Ford']\n",
    "damage_levels = ['No damage', 'Some damage', 'High damage']\n",
    "owner_types = [1, 2, 3]\n",
    "age_categories = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Generating data for the table\n",
    "data = []\n",
    "for asset_id in range(1, 101):  # Assuming 100 records\n",
    "    name = f'Vehicle_{asset_id}'\n",
    "    manufacturer = random.choice(manufacturers)\n",
    "    age = random.choice(age_categories)\n",
    "    damage = random.choice(damage_levels)\n",
    "    owner_number = random.choice(owner_types)\n",
    "    holder_id = random.choice(holder_ids)\n",
    "    loan_id = random.choice(loan_ids)\n",
    "\n",
    "    # Derive Model_type logic from vehicle_type\n",
    "    if random.choice([True, False]):\n",
    "        model_type = 'Two Wheeler'\n",
    "    else:\n",
    "        model_type = 'Four Wheeler'\n",
    "\n",
    "    data.append((asset_id, model_type, name, manufacturer, age, damage, owner_number, holder_id, loan_id))\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Asset_id', 'Model_type', 'Name', 'Manufacturer', 'Age', 'Damage', 'Owner_number', 'Holder_id', 'LoanId']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv('vehicle_details.csv', index=False)\n",
    "\n",
    "print(\"Data saved to 'vehicle_details.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Vehicle_Details VALUES (1,'Four Wheeler','Vehicle_1','Mustang',3,'High damage',3,25,'LP001055');\n",
      "INSERT INTO Vehicle_Details VALUES (2,'Four Wheeler','Vehicle_2','Honda',1,'No damage',1,1,'LP001174');\n",
      "INSERT INTO Vehicle_Details VALUES (3,'Two Wheeler','Vehicle_3','Honda',4,'Some damage',2,1,'LP001169');\n",
      "INSERT INTO Vehicle_Details VALUES (4,'Four Wheeler','Vehicle_4','Mazda',1,'Some damage',2,7,'LP001121');\n",
      "INSERT INTO Vehicle_Details VALUES (5,'Two Wheeler','Vehicle_5','Lincoln',2,'Some damage',3,12,'LP001067');\n",
      "INSERT INTO Vehicle_Details VALUES (6,'Two Wheeler','Vehicle_6','Mustang',1,'High damage',2,49,'LP001107');\n",
      "INSERT INTO Vehicle_Details VALUES (7,'Four Wheeler','Vehicle_7','Mustang',4,'No damage',1,39,'LP001105');\n",
      "INSERT INTO Vehicle_Details VALUES (8,'Two Wheeler','Vehicle_8','Mustang',5,'Some damage',2,39,'LP001230');\n",
      "INSERT INTO Vehicle_Details VALUES (9,'Two Wheeler','Vehicle_9','Lincoln',1,'High damage',3,15,'LP001022');\n",
      "INSERT INTO Vehicle_Details VALUES (10,'Two Wheeler','Vehicle_10','Audi',1,'High damage',2,46,'LP001174');\n",
      "INSERT INTO Vehicle_Details VALUES (11,'Two Wheeler','Vehicle_11','Mustang',3,'Some damage',2,3,'LP001094');\n",
      "INSERT INTO Vehicle_Details VALUES (12,'Four Wheeler','Vehicle_12','BMW',5,'High damage',2,37,'LP001015');\n",
      "INSERT INTO Vehicle_Details VALUES (13,'Four Wheeler','Vehicle_13','Audi',5,'High damage',2,37,'LP001153');\n",
      "INSERT INTO Vehicle_Details VALUES (14,'Four Wheeler','Vehicle_14','Ford',5,'High damage',3,8,'LP001059');\n",
      "INSERT INTO Vehicle_Details VALUES (15,'Two Wheeler','Vehicle_15','Audi',2,'High damage',1,5,'LP001231');\n",
      "INSERT INTO Vehicle_Details VALUES (16,'Four Wheeler','Vehicle_16','Honda',3,'High damage',1,47,'LP001135');\n",
      "INSERT INTO Vehicle_Details VALUES (17,'Four Wheeler','Vehicle_17','BMW',2,'No damage',3,28,'LP001051');\n",
      "INSERT INTO Vehicle_Details VALUES (18,'Four Wheeler','Vehicle_18','Mercedes',1,'No damage',3,22,'LP001031');\n",
      "INSERT INTO Vehicle_Details VALUES (19,'Two Wheeler','Vehicle_19','Ford',4,'High damage',3,32,'LP001169');\n",
      "INSERT INTO Vehicle_Details VALUES (20,'Four Wheeler','Vehicle_20','BMW',1,'No damage',2,2,'LP001291');\n",
      "INSERT INTO Vehicle_Details VALUES (21,'Four Wheeler','Vehicle_21','Lincoln',3,'No damage',1,29,'LP001108');\n",
      "INSERT INTO Vehicle_Details VALUES (22,'Two Wheeler','Vehicle_22','Mustang',4,'High damage',3,26,'LP001210');\n",
      "INSERT INTO Vehicle_Details VALUES (23,'Two Wheeler','Vehicle_23','Kia',2,'No damage',2,24,'LP001230');\n",
      "INSERT INTO Vehicle_Details VALUES (24,'Two Wheeler','Vehicle_24','BMW',4,'High damage',3,1,'LP001055');\n",
      "INSERT INTO Vehicle_Details VALUES (25,'Four Wheeler','Vehicle_25','Mazda',2,'Some damage',3,36,'LP001067');\n",
      "INSERT INTO Vehicle_Details VALUES (26,'Two Wheeler','Vehicle_26','Honda',1,'High damage',3,47,'LP001059');\n",
      "INSERT INTO Vehicle_Details VALUES (27,'Two Wheeler','Vehicle_27','Ford',5,'High damage',2,30,'LP001291');\n",
      "INSERT INTO Vehicle_Details VALUES (28,'Four Wheeler','Vehicle_28','Audi',4,'No damage',2,32,'LP001312');\n",
      "INSERT INTO Vehicle_Details VALUES (29,'Four Wheeler','Vehicle_29','Ford',4,'Some damage',2,10,'LP001284');\n",
      "INSERT INTO Vehicle_Details VALUES (30,'Two Wheeler','Vehicle_30','Honda',4,'No damage',2,33,'LP001096');\n",
      "INSERT INTO Vehicle_Details VALUES (31,'Two Wheeler','Vehicle_31','Mazda',3,'Some damage',2,48,'LP001022');\n",
      "INSERT INTO Vehicle_Details VALUES (32,'Four Wheeler','Vehicle_32','Lamborghini',4,'Some damage',2,30,'LP001149');\n",
      "INSERT INTO Vehicle_Details VALUES (33,'Four Wheeler','Vehicle_33','Lamborghini',1,'High damage',1,2,'LP001174');\n",
      "INSERT INTO Vehicle_Details VALUES (34,'Four Wheeler','Vehicle_34','Lamborghini',5,'No damage',1,15,'LP001221');\n",
      "INSERT INTO Vehicle_Details VALUES (35,'Two Wheeler','Vehicle_35','Maruti',3,'No damage',2,14,'LP001153');\n",
      "INSERT INTO Vehicle_Details VALUES (36,'Two Wheeler','Vehicle_36','Mustang',3,'No damage',1,27,'LP001124');\n",
      "INSERT INTO Vehicle_Details VALUES (37,'Two Wheeler','Vehicle_37','Mercedes',5,'Some damage',3,14,'LP001022');\n",
      "INSERT INTO Vehicle_Details VALUES (38,'Four Wheeler','Vehicle_38','Mercedes',2,'No damage',1,2,'LP001022');\n",
      "INSERT INTO Vehicle_Details VALUES (39,'Four Wheeler','Vehicle_39','Mercedes',1,'Some damage',3,11,'LP001099');\n",
      "INSERT INTO Vehicle_Details VALUES (40,'Four Wheeler','Vehicle_40','Mustang',3,'High damage',1,15,'LP001107');\n",
      "INSERT INTO Vehicle_Details VALUES (41,'Four Wheeler','Vehicle_41','BMW',4,'No damage',2,39,'LP001210');\n",
      "INSERT INTO Vehicle_Details VALUES (42,'Two Wheeler','Vehicle_42','Ford',3,'Some damage',1,35,'LP001105');\n",
      "INSERT INTO Vehicle_Details VALUES (43,'Four Wheeler','Vehicle_43','Mercedes',1,'Some damage',2,5,'LP001055');\n",
      "INSERT INTO Vehicle_Details VALUES (44,'Two Wheeler','Vehicle_44','Mercedes',1,'No damage',1,25,'LP001107');\n",
      "INSERT INTO Vehicle_Details VALUES (45,'Four Wheeler','Vehicle_45','Honda',3,'No damage',3,25,'LP001078');\n",
      "INSERT INTO Vehicle_Details VALUES (46,'Two Wheeler','Vehicle_46','Lamborghini',1,'High damage',3,25,'LP001208');\n",
      "INSERT INTO Vehicle_Details VALUES (47,'Four Wheeler','Vehicle_47','Mustang',1,'High damage',3,11,'LP001083');\n",
      "INSERT INTO Vehicle_Details VALUES (48,'Four Wheeler','Vehicle_48','Honda',5,'High damage',2,13,'LP001096');\n",
      "INSERT INTO Vehicle_Details VALUES (49,'Two Wheeler','Vehicle_49','Kia',1,'No damage',3,17,'LP001231');\n",
      "INSERT INTO Vehicle_Details VALUES (50,'Four Wheeler','Vehicle_50','Mercedes',1,'No damage',1,23,'LP001219');\n",
      "INSERT INTO Vehicle_Details VALUES (51,'Two Wheeler','Vehicle_51','Mazda',5,'High damage',3,39,'LP001055');\n",
      "INSERT INTO Vehicle_Details VALUES (52,'Four Wheeler','Vehicle_52','Mazda',1,'High damage',1,45,'LP001268');\n",
      "INSERT INTO Vehicle_Details VALUES (53,'Four Wheeler','Vehicle_53','Lincoln',1,'Some damage',2,6,'LP001059');\n",
      "INSERT INTO Vehicle_Details VALUES (54,'Two Wheeler','Vehicle_54','Ford',1,'No damage',2,40,'LP001190');\n",
      "INSERT INTO Vehicle_Details VALUES (55,'Two Wheeler','Vehicle_55','Mazda',1,'High damage',1,9,'LP001232');\n",
      "INSERT INTO Vehicle_Details VALUES (56,'Four Wheeler','Vehicle_56','Ford',2,'High damage',1,37,'LP001022');\n",
      "INSERT INTO Vehicle_Details VALUES (57,'Two Wheeler','Vehicle_57','Ford',2,'No damage',2,29,'LP001230');\n",
      "INSERT INTO Vehicle_Details VALUES (58,'Two Wheeler','Vehicle_58','BMW',5,'High damage',3,6,'LP001083');\n",
      "INSERT INTO Vehicle_Details VALUES (59,'Four Wheeler','Vehicle_59','Ford',4,'No damage',3,28,'LP001099');\n",
      "INSERT INTO Vehicle_Details VALUES (60,'Two Wheeler','Vehicle_60','Honda',1,'Some damage',3,33,'LP001242');\n",
      "INSERT INTO Vehicle_Details VALUES (61,'Four Wheeler','Vehicle_61','Honda',1,'Some damage',2,34,'LP001115');\n",
      "INSERT INTO Vehicle_Details VALUES (62,'Two Wheeler','Vehicle_62','Lamborghini',2,'High damage',3,20,'LP001056');\n",
      "INSERT INTO Vehicle_Details VALUES (63,'Four Wheeler','Vehicle_63','BMW',5,'Some damage',2,42,'LP001108');\n",
      "INSERT INTO Vehicle_Details VALUES (64,'Four Wheeler','Vehicle_64','Lamborghini',5,'No damage',3,47,'LP001149');\n",
      "INSERT INTO Vehicle_Details VALUES (65,'Two Wheeler','Vehicle_65','Lincoln',5,'High damage',2,37,'LP001187');\n",
      "INSERT INTO Vehicle_Details VALUES (66,'Four Wheeler','Vehicle_66','Honda',2,'Some damage',1,9,'LP001096');\n",
      "INSERT INTO Vehicle_Details VALUES (67,'Four Wheeler','Vehicle_67','Mercedes',3,'Some damage',1,7,'LP001232');\n",
      "INSERT INTO Vehicle_Details VALUES (68,'Four Wheeler','Vehicle_68','Mercedes',4,'High damage',2,24,'LP001124');\n",
      "INSERT INTO Vehicle_Details VALUES (69,'Two Wheeler','Vehicle_69','Maruti',1,'No damage',3,45,'LP001149');\n",
      "INSERT INTO Vehicle_Details VALUES (70,'Two Wheeler','Vehicle_70','Mustang',4,'High damage',3,7,'LP001015');\n",
      "INSERT INTO Vehicle_Details VALUES (71,'Two Wheeler','Vehicle_71','Maruti',2,'High damage',1,2,'LP001169');\n",
      "INSERT INTO Vehicle_Details VALUES (72,'Four Wheeler','Vehicle_72','Mustang',2,'High damage',3,3,'LP001210');\n",
      "INSERT INTO Vehicle_Details VALUES (73,'Four Wheeler','Vehicle_73','Ford',3,'High damage',3,14,'LP001230');\n",
      "INSERT INTO Vehicle_Details VALUES (74,'Two Wheeler','Vehicle_74','Ford',2,'No damage',3,26,'LP001108');\n",
      "INSERT INTO Vehicle_Details VALUES (75,'Two Wheeler','Vehicle_75','Mustang',4,'Some damage',3,7,'LP001059');\n",
      "INSERT INTO Vehicle_Details VALUES (76,'Four Wheeler','Vehicle_76','Audi',3,'Some damage',2,25,'LP001203');\n",
      "INSERT INTO Vehicle_Details VALUES (77,'Four Wheeler','Vehicle_77','Honda',4,'High damage',2,39,'LP001183');\n",
      "INSERT INTO Vehicle_Details VALUES (78,'Two Wheeler','Vehicle_78','BMW',4,'High damage',2,14,'LP001221');\n",
      "INSERT INTO Vehicle_Details VALUES (79,'Four Wheeler','Vehicle_79','Kia',4,'No damage',2,46,'LP001149');\n",
      "INSERT INTO Vehicle_Details VALUES (80,'Two Wheeler','Vehicle_80','Maruti',2,'High damage',3,7,'LP001176');\n",
      "INSERT INTO Vehicle_Details VALUES (81,'Two Wheeler','Vehicle_81','Honda',3,'No damage',1,47,'LP001187');\n",
      "INSERT INTO Vehicle_Details VALUES (82,'Four Wheeler','Vehicle_82','Honda',1,'Some damage',2,44,'LP001128');\n",
      "INSERT INTO Vehicle_Details VALUES (83,'Four Wheeler','Vehicle_83','BMW',4,'Some damage',2,44,'LP001284');\n",
      "INSERT INTO Vehicle_Details VALUES (84,'Two Wheeler','Vehicle_84','Honda',5,'Some damage',2,21,'LP001078');\n",
      "INSERT INTO Vehicle_Details VALUES (85,'Four Wheeler','Vehicle_85','Maruti',2,'High damage',2,38,'LP001163');\n",
      "INSERT INTO Vehicle_Details VALUES (86,'Two Wheeler','Vehicle_86','Ford',2,'Some damage',2,33,'LP001169');\n",
      "INSERT INTO Vehicle_Details VALUES (87,'Two Wheeler','Vehicle_87','Audi',2,'High damage',1,34,'LP001298');\n",
      "INSERT INTO Vehicle_Details VALUES (88,'Four Wheeler','Vehicle_88','Mazda',2,'No damage',2,36,'LP001226');\n",
      "INSERT INTO Vehicle_Details VALUES (89,'Two Wheeler','Vehicle_89','Lincoln',2,'No damage',3,32,'LP001056');\n",
      "INSERT INTO Vehicle_Details VALUES (90,'Four Wheeler','Vehicle_90','Kia',1,'High damage',3,49,'LP001059');\n",
      "INSERT INTO Vehicle_Details VALUES (91,'Two Wheeler','Vehicle_91','Kia',1,'No damage',2,24,'LP001107');\n",
      "INSERT INTO Vehicle_Details VALUES (92,'Two Wheeler','Vehicle_92','Lamborghini',4,'Some damage',3,47,'LP001208');\n",
      "INSERT INTO Vehicle_Details VALUES (93,'Two Wheeler','Vehicle_93','BMW',4,'Some damage',2,10,'LP001190');\n",
      "INSERT INTO Vehicle_Details VALUES (94,'Four Wheeler','Vehicle_94','Kia',1,'High damage',2,36,'LP001083');\n",
      "INSERT INTO Vehicle_Details VALUES (95,'Four Wheeler','Vehicle_95','Audi',4,'High damage',2,5,'LP001128');\n",
      "INSERT INTO Vehicle_Details VALUES (96,'Two Wheeler','Vehicle_96','Lamborghini',5,'Some damage',3,50,'LP001121');\n",
      "INSERT INTO Vehicle_Details VALUES (97,'Four Wheeler','Vehicle_97','Kia',3,'High damage',1,9,'LP001185');\n",
      "INSERT INTO Vehicle_Details VALUES (98,'Four Wheeler','Vehicle_98','Mercedes',5,'No damage',3,50,'LP001190');\n",
      "INSERT INTO Vehicle_Details VALUES (99,'Two Wheeler','Vehicle_99','Honda',2,'Some damage',2,38,'LP001268');\n",
      "INSERT INTO Vehicle_Details VALUES (100,'Four Wheeler','Vehicle_100','Lamborghini',3,'No damage',1,4,'LP001022');\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Vehicle_Details table\n",
    "for Asset_id, Model_type, Name, Manufacturer, Age, Damage, Owner_number, Holder_id, LoanId  in df.values.tolist():\n",
    "    print(\"INSERT INTO Vehicle_Details VALUES ({},'{}','{}','{}',{},'{}',{},{},'{}');\".format(Asset_id, Model_type, Name, Manufacturer, Age, Damage, Owner_number, Holder_id, LoanId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Asset_id                                            Address  Carpet_area  \\\n",
      "0          1     369 Nicole Courts Apt. 390\\nSotofurt, MP 46969         40.0   \n",
      "1          2  88846 Michael Rapid Apt. 509\\nNew Ryanfurt, NY...         42.0   \n",
      "2          3           58138 Paul Trail\\nPort Kristen, PA 22627         45.0   \n",
      "3          4    125 Wyatt Fords Suite 874\\nLake Emily, NM 03235         46.0   \n",
      "4          5  63759 Graham Wells Suite 913\\nMillerchester, M...         55.0   \n",
      "5          6  96275 Brian Lakes Apt. 664\\nMelissamouth, VT 0...         55.0   \n",
      "6          7                   PSC 7700, Box 1021\\nAPO AE 97757         60.0   \n",
      "7          8   0033 Chan Hills Apt. 643\\nNew Rogerton, CO 94460         62.0   \n",
      "8          9  2657 Rebecca Locks Suite 354\\nGarrettton, MP 8...         64.0   \n",
      "9         10            650 West Orchard\\nCynthiafurt, UT 50554         65.0   \n",
      "10        11   821 Jill Light Suite 863\\nCarrilloside, KS 06662         65.0   \n",
      "11        12        521 Robin Motorway\\nChristineberg, AS 64097         65.0   \n",
      "12        13  20126 Kathryn Mission Suite 582\\nNew Jaredches...         65.0   \n",
      "13        14         0622 Jones Greens\\nAndreachester, WV 71705         65.0   \n",
      "14        15  832 Daniel Motorway Suite 328\\nAmandaton, NY 7...         65.0   \n",
      "15        16                   Unit 1246 Box 9663\\nDPO AE 12049         65.0   \n",
      "16        17   32531 Mclean Street\\nEast Williammouth, UT 28268         67.0   \n",
      "17        18  23637 Monica Streets Suite 959\\nSouth Randall,...         68.0   \n",
      "18        19           3901 Adam Branch\\nMichelleview, NJ 43124         70.0   \n",
      "19        20             417 Ray Trail\\nAndersonmouth, AR 40879         70.0   \n",
      "20        21  7653 Vaughn Stream Suite 982\\nLake Kathyside, ...         70.0   \n",
      "21        22                   Unit 2038 Box 7064\\nDPO AE 64593         70.0   \n",
      "22        23        35783 Amber Highway\\nPort Ianfurt, DE 85703         70.0   \n",
      "23        24          5815 Wolf Via\\nNorth Nicoleland, IN 78109         70.0   \n",
      "24        25                          USNS French\\nFPO AA 42194         70.0   \n",
      "25        26  2270 Hopkins Coves Suite 360\\nMatthewton, NE 6...         73.0   \n",
      "26        27          050 Lopez Spring\\nWest Maryport, CT 10905         75.0   \n",
      "27        28   41102 Timothy Mountain\\nWest Alexhaven, HI 09554         75.0   \n",
      "28        29  63343 Michael Spur Apt. 663\\nSouth Jennifer, O...         75.0   \n",
      "29        30                   PSC 3631, Box 0160\\nAPO AE 85245         75.0   \n",
      "30        31         219 Andre Shoal\\nWest Kathrynton, MD 45754         75.0   \n",
      "31        32      9040 Leblanc Canyon\\nGabrielborough, MD 81094         80.0   \n",
      "32        33  382 Reyes Bridge Apt. 682\\nPort Stephen, SC 37996         80.0   \n",
      "33        34          2219 Matthew Island\\nRhondaland, DE 01336         80.0   \n",
      "34        35  641 Morrison Forges Apt. 087\\nEast Jennifervie...         80.0   \n",
      "35        36           0386 Mckay Plains\\nNorth Erica, MD 45002         80.0   \n",
      "36        37   72001 Hill Greens Suite 216\\nPatelbury, MA 74804         80.0   \n",
      "37        38          28306 Hodge River\\nStephenville, AK 52107         80.0   \n",
      "38        39          745 Sharp Prairie\\nSouth Steven, IA 85101         82.0   \n",
      "39        40           136 Garcia Plain\\nWest Heather, NM 88649         83.0   \n",
      "40        41  17009 Shelby Court Suite 424\\nNew Jenniferfurt...         84.0   \n",
      "41        42   2731 Tyler Spurs Suite 572\\nJosephfurt, AS 72150         85.0   \n",
      "42        43         362 Sherman Burg\\nPort Alejandro, AS 24307         85.0   \n",
      "43        44  3008 Walker Forge Suite 715\\nEast Meganfort, M...         86.0   \n",
      "44        45    7545 Davis Drive Suite 424\\nMasonside, KY 14942         90.0   \n",
      "45        46            93981 Dean Cliff\\nNorth Becky, OK 01751         90.0   \n",
      "46        47   5581 Rojas Avenue Apt. 292\\nAyersburgh, MO 36844         90.0   \n",
      "47        48  773 Brandy Villages Apt. 694\\nHernandezland, N...         90.0   \n",
      "48        49  3977 Baker Meadow Suite 458\\nWest Tiffany, DC ...         90.0   \n",
      "49        50            642 Cindy Union\\nWallaceburgh, AK 61871         95.0   \n",
      "\n",
      "   Construction_type  Estimated_market_value  Year_built  Holder_id    LoanId  \n",
      "0                New                  450622           2         42  LP001177  \n",
      "1                Old                  321747          18         11  LP001211  \n",
      "2                New                   93303           8         11  LP001051  \n",
      "3                New                  428373           4         27  LP001115  \n",
      "4                New                  361192           2          1  LP001082  \n",
      "5                Old                  315519          19         47  LP001051  \n",
      "6                New                   59893          10         36  LP001270  \n",
      "7                Old                   69443          15         50  LP001121  \n",
      "8                New                  290560           4         42  LP001015  \n",
      "9                Old                   53307          15         15  LP001056  \n",
      "10               New                  464263           5         33  LP001187  \n",
      "11               Old                  366989          14         11  LP001015  \n",
      "12               Old                  249549          11         13  LP001284  \n",
      "13               Old                  273639          20         48  LP001124  \n",
      "14               Old                  328137          13         29  LP001121  \n",
      "15               Old                  185267          17         48  LP001096  \n",
      "16               Old                  492915          12         15  LP001054  \n",
      "17               New                  342244           4         29  LP001176  \n",
      "18               Old                  224774          17         21  LP001177  \n",
      "19               New                   67592           1         47  LP001135  \n",
      "20               Old                  337652          12          8  LP001121  \n",
      "21               Old                   91851          13         21  LP001105  \n",
      "22               Old                  414380          15         19  LP001051  \n",
      "23               Old                  390197          13         41  LP001174  \n",
      "24               New                  374406           3         43  LP001291  \n",
      "25               Old                  121602          17         40  LP001183  \n",
      "26               New                  349179           6         39  LP001231  \n",
      "27               Old                  140179          12         41  LP001219  \n",
      "28               New                  444146           1         15  LP001031  \n",
      "29               New                  468881           4         34  LP001035  \n",
      "30               Old                  214312          19         23  LP001190  \n",
      "31               New                  318681           1          5  LP001054  \n",
      "32               New                  106127           3         46  LP001056  \n",
      "33               Old                  256767          18         36  LP001174  \n",
      "34               New                  496832           1         46  LP001022  \n",
      "35               New                  482604           1          7  LP001203  \n",
      "36               New                  391848           1          4  LP001135  \n",
      "37               New                   69468           7         22  LP001149  \n",
      "38               Old                  141166          16          7  LP001124  \n",
      "39               Old                  301471          16          4  LP001124  \n",
      "40               Old                  360897          12         11  LP001208  \n",
      "41               New                  232975           2         36  LP001015  \n",
      "42               New                  464857          10         26  LP001169  \n",
      "43               New                  133442           1         43  LP001096  \n",
      "44               Old                  274577          19         24  LP001035  \n",
      "45               New                  457625           3         38  LP001210  \n",
      "46               New                  272200           9         50  LP001163  \n",
      "47               Old                  368014          20         42  LP001153  \n",
      "48               New                  122151           6          3  LP001107  \n",
      "49               New                  495212          10         30  LP001174  \n"
     ]
    }
   ],
   "source": [
    "# Working on Home_Details\n",
    "# I'll be using a file that i got from kaggle and also generating some random data for missing columns\n",
    "# reference - https://www.kaggle.com/datasets/emrahaydemr/home-sales-data-details-in-istanbul\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import faker\n",
    "\n",
    "holder_ids = list(range(1, 51))\n",
    "loan_ids = ['LP001015', 'LP001022', 'LP001031', 'LP001035', 'LP001051', 'LP001054', 'LP001055', 'LP001056', 'LP001059',\n",
    "            'LP001067', 'LP001078', 'LP001082', 'LP001083', 'LP001094', 'LP001096', 'LP001099', 'LP001105', 'LP001107',\n",
    "            'LP001108', 'LP001115', 'LP001121', 'LP001124', 'LP001128', 'LP001135', 'LP001149', 'LP001153', 'LP001163',\n",
    "            'LP001169', 'LP001174', 'LP001176', 'LP001177', 'LP001183', 'LP001185', 'LP001187', 'LP001190', 'LP001203',\n",
    "            'LP001208', 'LP001210', 'LP001211', 'LP001219', 'LP001220', 'LP001221', 'LP001226', 'LP001230', 'LP001231',\n",
    "            'LP001232', 'LP001237', 'LP001242', 'LP001268', 'LP001270', 'LP001284', 'LP001287', 'LP001291', 'LP001298',\n",
    "            'LP001312']\n",
    "\n",
    "# Initialize the Faker generator for USA addresses\n",
    "fake = faker.Faker('en_US')\n",
    "\n",
    "# Assuming 'your_data.csv' is the file containing your data\n",
    "df = pd.read_csv('Home Sale Data.csv', delimiter=';')\n",
    "\n",
    "# Create a new DataFrame with the desired columns and only 50 rows\n",
    "new_df = pd.DataFrame(columns=['Asset_id', 'Address', 'Carpet_area', 'Construction_type', 'Estimated_market_value',\n",
    "                               'Year_built', 'Holder_id', 'LoanId'])\n",
    "\n",
    "# Set the primary key (Asset_id) as integers starting from 1\n",
    "new_df['Asset_id'] = np.arange(1, 51)\n",
    "\n",
    "# Use the columns that are similar to the attributes in the table\n",
    "new_df['Carpet_area'] = df['m² (Net)'].head(50)  # Assuming 'm² (Net)' is the carpet area column\n",
    "new_df['Estimated_market_value'] = np.random.randint(50000, 500000, 50)  # Random market values\n",
    "\n",
    "# Use the provided 'year' list for the 'Year_built' column\n",
    "new_df['Year_built'] = random.choices([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], k=50)\n",
    "\n",
    "# Set Construction_type as 'Old' if Year_built > 10, else 'New'\n",
    "new_df['Construction_type'] = np.where(new_df['Year_built'] > 10, 'Old', 'New')\n",
    "\n",
    "# Generate random Holder_id and LoanId based on the provided lists\n",
    "new_df['Holder_id'] = random.choices(holder_ids, k=50)\n",
    "new_df['LoanId'] = random.choices(loan_ids, k=50)\n",
    "\n",
    "# Generate random USA addresses\n",
    "new_df['Address'] = [fake.address() for _ in range(50)]\n",
    "\n",
    "\n",
    "print(new_df)\n",
    "new_df.to_csv('Home_Details.csv', index=False)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Home_Details VALUES (1,'369 Nicole Courts Apt. 390\n",
      "Sotofurt, MP 46969',40.0,'New',450622,2,42,'LP001177');\n",
      "INSERT INTO Home_Details VALUES (2,'88846 Michael Rapid Apt. 509\n",
      "New Ryanfurt, NY 09603',42.0,'Old',321747,18,11,'LP001211');\n",
      "INSERT INTO Home_Details VALUES (3,'58138 Paul Trail\n",
      "Port Kristen, PA 22627',45.0,'New',93303,8,11,'LP001051');\n",
      "INSERT INTO Home_Details VALUES (4,'125 Wyatt Fords Suite 874\n",
      "Lake Emily, NM 03235',46.0,'New',428373,4,27,'LP001115');\n",
      "INSERT INTO Home_Details VALUES (5,'63759 Graham Wells Suite 913\n",
      "Millerchester, MH 95793',55.0,'New',361192,2,1,'LP001082');\n",
      "INSERT INTO Home_Details VALUES (6,'96275 Brian Lakes Apt. 664\n",
      "Melissamouth, VT 06002',55.0,'Old',315519,19,47,'LP001051');\n",
      "INSERT INTO Home_Details VALUES (7,'PSC 7700, Box 1021\n",
      "APO AE 97757',60.0,'New',59893,10,36,'LP001270');\n",
      "INSERT INTO Home_Details VALUES (8,'0033 Chan Hills Apt. 643\n",
      "New Rogerton, CO 94460',62.0,'Old',69443,15,50,'LP001121');\n",
      "INSERT INTO Home_Details VALUES (9,'2657 Rebecca Locks Suite 354\n",
      "Garrettton, MP 85073',64.0,'New',290560,4,42,'LP001015');\n",
      "INSERT INTO Home_Details VALUES (10,'650 West Orchard\n",
      "Cynthiafurt, UT 50554',65.0,'Old',53307,15,15,'LP001056');\n",
      "INSERT INTO Home_Details VALUES (11,'821 Jill Light Suite 863\n",
      "Carrilloside, KS 06662',65.0,'New',464263,5,33,'LP001187');\n",
      "INSERT INTO Home_Details VALUES (12,'521 Robin Motorway\n",
      "Christineberg, AS 64097',65.0,'Old',366989,14,11,'LP001015');\n",
      "INSERT INTO Home_Details VALUES (13,'20126 Kathryn Mission Suite 582\n",
      "New Jaredchester, MO 00733',65.0,'Old',249549,11,13,'LP001284');\n",
      "INSERT INTO Home_Details VALUES (14,'0622 Jones Greens\n",
      "Andreachester, WV 71705',65.0,'Old',273639,20,48,'LP001124');\n",
      "INSERT INTO Home_Details VALUES (15,'832 Daniel Motorway Suite 328\n",
      "Amandaton, NY 72196',65.0,'Old',328137,13,29,'LP001121');\n",
      "INSERT INTO Home_Details VALUES (16,'Unit 1246 Box 9663\n",
      "DPO AE 12049',65.0,'Old',185267,17,48,'LP001096');\n",
      "INSERT INTO Home_Details VALUES (17,'32531 Mclean Street\n",
      "East Williammouth, UT 28268',67.0,'Old',492915,12,15,'LP001054');\n",
      "INSERT INTO Home_Details VALUES (18,'23637 Monica Streets Suite 959\n",
      "South Randall, WA 84130',68.0,'New',342244,4,29,'LP001176');\n",
      "INSERT INTO Home_Details VALUES (19,'3901 Adam Branch\n",
      "Michelleview, NJ 43124',70.0,'Old',224774,17,21,'LP001177');\n",
      "INSERT INTO Home_Details VALUES (20,'417 Ray Trail\n",
      "Andersonmouth, AR 40879',70.0,'New',67592,1,47,'LP001135');\n",
      "INSERT INTO Home_Details VALUES (21,'7653 Vaughn Stream Suite 982\n",
      "Lake Kathyside, NC 62080',70.0,'Old',337652,12,8,'LP001121');\n",
      "INSERT INTO Home_Details VALUES (22,'Unit 2038 Box 7064\n",
      "DPO AE 64593',70.0,'Old',91851,13,21,'LP001105');\n",
      "INSERT INTO Home_Details VALUES (23,'35783 Amber Highway\n",
      "Port Ianfurt, DE 85703',70.0,'Old',414380,15,19,'LP001051');\n",
      "INSERT INTO Home_Details VALUES (24,'5815 Wolf Via\n",
      "North Nicoleland, IN 78109',70.0,'Old',390197,13,41,'LP001174');\n",
      "INSERT INTO Home_Details VALUES (25,'USNS French\n",
      "FPO AA 42194',70.0,'New',374406,3,43,'LP001291');\n",
      "INSERT INTO Home_Details VALUES (26,'2270 Hopkins Coves Suite 360\n",
      "Matthewton, NE 63831',73.0,'Old',121602,17,40,'LP001183');\n",
      "INSERT INTO Home_Details VALUES (27,'050 Lopez Spring\n",
      "West Maryport, CT 10905',75.0,'New',349179,6,39,'LP001231');\n",
      "INSERT INTO Home_Details VALUES (28,'41102 Timothy Mountain\n",
      "West Alexhaven, HI 09554',75.0,'Old',140179,12,41,'LP001219');\n",
      "INSERT INTO Home_Details VALUES (29,'63343 Michael Spur Apt. 663\n",
      "South Jennifer, OH 62658',75.0,'New',444146,1,15,'LP001031');\n",
      "INSERT INTO Home_Details VALUES (30,'PSC 3631, Box 0160\n",
      "APO AE 85245',75.0,'New',468881,4,34,'LP001035');\n",
      "INSERT INTO Home_Details VALUES (31,'219 Andre Shoal\n",
      "West Kathrynton, MD 45754',75.0,'Old',214312,19,23,'LP001190');\n",
      "INSERT INTO Home_Details VALUES (32,'9040 Leblanc Canyon\n",
      "Gabrielborough, MD 81094',80.0,'New',318681,1,5,'LP001054');\n",
      "INSERT INTO Home_Details VALUES (33,'382 Reyes Bridge Apt. 682\n",
      "Port Stephen, SC 37996',80.0,'New',106127,3,46,'LP001056');\n",
      "INSERT INTO Home_Details VALUES (34,'2219 Matthew Island\n",
      "Rhondaland, DE 01336',80.0,'Old',256767,18,36,'LP001174');\n",
      "INSERT INTO Home_Details VALUES (35,'641 Morrison Forges Apt. 087\n",
      "East Jenniferview, RI 26167',80.0,'New',496832,1,46,'LP001022');\n",
      "INSERT INTO Home_Details VALUES (36,'0386 Mckay Plains\n",
      "North Erica, MD 45002',80.0,'New',482604,1,7,'LP001203');\n",
      "INSERT INTO Home_Details VALUES (37,'72001 Hill Greens Suite 216\n",
      "Patelbury, MA 74804',80.0,'New',391848,1,4,'LP001135');\n",
      "INSERT INTO Home_Details VALUES (38,'28306 Hodge River\n",
      "Stephenville, AK 52107',80.0,'New',69468,7,22,'LP001149');\n",
      "INSERT INTO Home_Details VALUES (39,'745 Sharp Prairie\n",
      "South Steven, IA 85101',82.0,'Old',141166,16,7,'LP001124');\n",
      "INSERT INTO Home_Details VALUES (40,'136 Garcia Plain\n",
      "West Heather, NM 88649',83.0,'Old',301471,16,4,'LP001124');\n",
      "INSERT INTO Home_Details VALUES (41,'17009 Shelby Court Suite 424\n",
      "New Jenniferfurt, DC 11319',84.0,'Old',360897,12,11,'LP001208');\n",
      "INSERT INTO Home_Details VALUES (42,'2731 Tyler Spurs Suite 572\n",
      "Josephfurt, AS 72150',85.0,'New',232975,2,36,'LP001015');\n",
      "INSERT INTO Home_Details VALUES (43,'362 Sherman Burg\n",
      "Port Alejandro, AS 24307',85.0,'New',464857,10,26,'LP001169');\n",
      "INSERT INTO Home_Details VALUES (44,'3008 Walker Forge Suite 715\n",
      "East Meganfort, MD 60946',86.0,'New',133442,1,43,'LP001096');\n",
      "INSERT INTO Home_Details VALUES (45,'7545 Davis Drive Suite 424\n",
      "Masonside, KY 14942',90.0,'Old',274577,19,24,'LP001035');\n",
      "INSERT INTO Home_Details VALUES (46,'93981 Dean Cliff\n",
      "North Becky, OK 01751',90.0,'New',457625,3,38,'LP001210');\n",
      "INSERT INTO Home_Details VALUES (47,'5581 Rojas Avenue Apt. 292\n",
      "Ayersburgh, MO 36844',90.0,'New',272200,9,50,'LP001163');\n",
      "INSERT INTO Home_Details VALUES (48,'773 Brandy Villages Apt. 694\n",
      "Hernandezland, NM 57251',90.0,'Old',368014,20,42,'LP001153');\n",
      "INSERT INTO Home_Details VALUES (49,'3977 Baker Meadow Suite 458\n",
      "West Tiffany, DC 24931',90.0,'New',122151,6,3,'LP001107');\n",
      "INSERT INTO Home_Details VALUES (50,'642 Cindy Union\n",
      "Wallaceburgh, AK 61871',95.0,'New',495212,10,30,'LP001174');\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Home_Details table\n",
    "for Asset_id, Address, Carpet_area, Construction_type, Estimated_market_value, Year_built, Holder_id, LoanId  in new_df.values.tolist():\n",
    "    print(\"INSERT INTO Home_Details VALUES ({},'{}',{},'{}',{},{},{},'{}');\".format(Asset_id, Address, Carpet_area, Construction_type, Estimated_market_value, Year_built, Holder_id, LoanId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Claim_id  Claim_amount        Date  Holder_id\n",
      "0       8270          4943  2022-01-01         32\n",
      "1       1860         24939  2022-01-15          2\n",
      "2       6390         20457  2022-01-30         14\n",
      "3       6191          2021  2022-02-14         12\n",
      "4       6734         12653  2022-03-01         37\n",
      "5       7265         44573  2022-03-16         34\n",
      "6       1466         14417  2022-03-31         45\n",
      "7       5426         41757  2022-04-15          5\n",
      "8       6578         10692  2022-04-30         22\n",
      "9       9322         46758  2022-05-14          2\n",
      "10      2685          7873  2022-05-29         11\n",
      "11      1769          6675  2022-06-13         26\n",
      "12      7949          1161  2022-06-28          2\n",
      "13      3433         38065  2022-07-13         10\n",
      "14      6311         27557  2022-07-28         33\n",
      "15      6051         34763  2022-08-12         28\n",
      "16      7420         33606  2022-08-27         12\n",
      "17      2184         12534  2022-09-10         30\n",
      "18      5555         30127  2022-09-25         41\n",
      "19      4385         41397  2022-10-10          1\n",
      "20      7396         26851  2022-10-25         41\n",
      "21      9666          2016  2022-11-09         35\n",
      "22      3558         25253  2022-11-24         18\n",
      "23      8849         25276  2022-12-09          8\n",
      "24      3047         24247  2022-12-24         48\n",
      "25      3747         25300  2023-01-07         17\n",
      "26      1189          9529  2023-01-22          5\n",
      "27      3734         18262  2023-02-06          5\n",
      "28      4005         10268  2023-02-21         43\n",
      "29      5658         22271  2023-03-08         31\n",
      "30      2899         13185  2023-03-23         41\n",
      "31      8734         22243  2023-04-07         37\n",
      "32      2267         40099  2023-04-22         27\n",
      "33      2528          9571  2023-05-06         49\n",
      "34      4556         40976  2023-05-21         19\n",
      "35      4890         39044  2023-06-05         28\n",
      "36      9838         49984  2023-06-20         42\n",
      "37      6393         41774  2023-07-05         31\n",
      "38      9792          3568  2023-07-20         44\n",
      "39      9433          3027  2023-08-04         29\n",
      "40      8513          3695  2023-08-19         36\n",
      "41      3612         49190  2023-09-02          3\n",
      "42      8041          6258  2023-09-17         12\n",
      "43      7235         23002  2023-10-02         15\n",
      "44      6486         40504  2023-10-17          4\n",
      "45      8099         34159  2023-11-01         12\n",
      "46      1775         14986  2023-11-16          6\n",
      "47      9226         13666  2023-12-01         14\n",
      "48      4152         39660  2023-12-16         32\n",
      "49      2585          4561  2023-12-31         19\n"
     ]
    }
   ],
   "source": [
    "#working on Claim table\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Generate random data for the Claim table\n",
    "fake = Faker()\n",
    "num_records = 50  # Limit to 50 rows\n",
    "\n",
    "# Generate random Claim_id, Claim_amount, Date, and Holder_id\n",
    "claim_ids = np.random.randint(1000, 10000, num_records)\n",
    "claim_amounts = np.random.randint(1000, 50000, num_records)\n",
    "dates = pd.date_range(start='2022-01-01', end='2023-12-31', periods=num_records)\n",
    "holder_ids = random.choices(range(1, 51), k=num_records)\n",
    "\n",
    "# Create a DataFrame with the generated data\n",
    "claim_data = pd.DataFrame({\n",
    "    'Claim_id': claim_ids,\n",
    "    'Claim_amount': claim_amounts,\n",
    "    'Date': dates,\n",
    "    'Holder_id': holder_ids\n",
    "})\n",
    "\n",
    "# Format the Date column to YYYY-MM-DD\n",
    "claim_data['Date'] = claim_data['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Print or use the resulting DataFrame as needed\n",
    "print(claim_data)\n",
    "\n",
    "claim_data.to_csv('Claim.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Claim VALUES (8270,4943,'2022-01-01',32);\n",
      "INSERT INTO Claim VALUES (1860,24939,'2022-01-15',2);\n",
      "INSERT INTO Claim VALUES (6390,20457,'2022-01-30',14);\n",
      "INSERT INTO Claim VALUES (6191,2021,'2022-02-14',12);\n",
      "INSERT INTO Claim VALUES (6734,12653,'2022-03-01',37);\n",
      "INSERT INTO Claim VALUES (7265,44573,'2022-03-16',34);\n",
      "INSERT INTO Claim VALUES (1466,14417,'2022-03-31',45);\n",
      "INSERT INTO Claim VALUES (5426,41757,'2022-04-15',5);\n",
      "INSERT INTO Claim VALUES (6578,10692,'2022-04-30',22);\n",
      "INSERT INTO Claim VALUES (9322,46758,'2022-05-14',2);\n",
      "INSERT INTO Claim VALUES (2685,7873,'2022-05-29',11);\n",
      "INSERT INTO Claim VALUES (1769,6675,'2022-06-13',26);\n",
      "INSERT INTO Claim VALUES (7949,1161,'2022-06-28',2);\n",
      "INSERT INTO Claim VALUES (3433,38065,'2022-07-13',10);\n",
      "INSERT INTO Claim VALUES (6311,27557,'2022-07-28',33);\n",
      "INSERT INTO Claim VALUES (6051,34763,'2022-08-12',28);\n",
      "INSERT INTO Claim VALUES (7420,33606,'2022-08-27',12);\n",
      "INSERT INTO Claim VALUES (2184,12534,'2022-09-10',30);\n",
      "INSERT INTO Claim VALUES (5555,30127,'2022-09-25',41);\n",
      "INSERT INTO Claim VALUES (4385,41397,'2022-10-10',1);\n",
      "INSERT INTO Claim VALUES (7396,26851,'2022-10-25',41);\n",
      "INSERT INTO Claim VALUES (9666,2016,'2022-11-09',35);\n",
      "INSERT INTO Claim VALUES (3558,25253,'2022-11-24',18);\n",
      "INSERT INTO Claim VALUES (8849,25276,'2022-12-09',8);\n",
      "INSERT INTO Claim VALUES (3047,24247,'2022-12-24',48);\n",
      "INSERT INTO Claim VALUES (3747,25300,'2023-01-07',17);\n",
      "INSERT INTO Claim VALUES (1189,9529,'2023-01-22',5);\n",
      "INSERT INTO Claim VALUES (3734,18262,'2023-02-06',5);\n",
      "INSERT INTO Claim VALUES (4005,10268,'2023-02-21',43);\n",
      "INSERT INTO Claim VALUES (5658,22271,'2023-03-08',31);\n",
      "INSERT INTO Claim VALUES (2899,13185,'2023-03-23',41);\n",
      "INSERT INTO Claim VALUES (8734,22243,'2023-04-07',37);\n",
      "INSERT INTO Claim VALUES (2267,40099,'2023-04-22',27);\n",
      "INSERT INTO Claim VALUES (2528,9571,'2023-05-06',49);\n",
      "INSERT INTO Claim VALUES (4556,40976,'2023-05-21',19);\n",
      "INSERT INTO Claim VALUES (4890,39044,'2023-06-05',28);\n",
      "INSERT INTO Claim VALUES (9838,49984,'2023-06-20',42);\n",
      "INSERT INTO Claim VALUES (6393,41774,'2023-07-05',31);\n",
      "INSERT INTO Claim VALUES (9792,3568,'2023-07-20',44);\n",
      "INSERT INTO Claim VALUES (9433,3027,'2023-08-04',29);\n",
      "INSERT INTO Claim VALUES (8513,3695,'2023-08-19',36);\n",
      "INSERT INTO Claim VALUES (3612,49190,'2023-09-02',3);\n",
      "INSERT INTO Claim VALUES (8041,6258,'2023-09-17',12);\n",
      "INSERT INTO Claim VALUES (7235,23002,'2023-10-02',15);\n",
      "INSERT INTO Claim VALUES (6486,40504,'2023-10-17',4);\n",
      "INSERT INTO Claim VALUES (8099,34159,'2023-11-01',12);\n",
      "INSERT INTO Claim VALUES (1775,14986,'2023-11-16',6);\n",
      "INSERT INTO Claim VALUES (9226,13666,'2023-12-01',14);\n",
      "INSERT INTO Claim VALUES (4152,39660,'2023-12-16',32);\n",
      "INSERT INTO Claim VALUES (2585,4561,'2023-12-31',19);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Claim table\n",
    "for Claim_id, Claim_amount, Date, Holder_id  in claim_data.values.tolist():\n",
    "    print(\"INSERT INTO Claim VALUES ({},{},'{}',{});\".format(Claim_id, Claim_amount, Date, Holder_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv('customer.csv')\n",
    "df_temp = df_temp['id']\n",
    "df_temp.to_csv('/Users/karanbadlani/Library/Mobile Documents/com~apple~CloudDocs/Desktop/temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Transaction_id        Date status_of_transaction  Amount  Customer_id  \\\n",
      "405253         098725  2017-03-10               Pending   49668       632251   \n",
      "151544         603071  2017-03-21               Pending   18303       915790   \n",
      "426715         136633  2017-07-11                Failed   16434       847339   \n",
      "222061         152754  2017-04-29                Failed   46570       867938   \n",
      "266453         616393  2017-05-16                Failed   44055       166248   \n",
      "335989         926484  2017-05-08             Completed   15151       174408   \n",
      "97388          205872  2017-10-01                Failed    2756       365390   \n",
      "303029         586079  2017-07-28                Failed   24303       358893   \n",
      "75745          028129  2017-01-31                Failed   29118       166248   \n",
      "189429         793896  2017-09-05                Failed    6691       591642   \n",
      "80497          830021  2017-01-20             Completed   17164       628418   \n",
      "124804         726836  2017-08-30               Pending   26063       336850   \n",
      "41887          775668  2017-10-01                Failed   33701       176254   \n",
      "350053         254957  2017-08-19               Pending   14749       358893   \n",
      "315587         189198  2017-08-19             Completed   24353       638484   \n",
      "11952          454793  2017-06-09               Pending    1660       554593   \n",
      "63008          271127  2017-09-01                Failed   12003       981115   \n",
      "403690         309030  2017-10-21               Pending   16926       166248   \n",
      "213659         409634  2017-09-05               Pending   23282       950610   \n",
      "306800         557235  2017-02-08             Completed   30481       176254   \n",
      "306540         451003  2017-11-10                Failed   37036       415216   \n",
      "22531          132434  2017-04-01               Pending    1420       987673   \n",
      "277639         797901  2017-11-21             Completed   37535       867938   \n",
      "435962         603560  2017-12-30                Failed   44263       867938   \n",
      "353425         651645  2017-08-17                Failed   45991       867938   \n",
      "21565          306533  2017-06-01             Completed   40435       871428   \n",
      "195155         614899  2017-09-05             Completed   35387       555849   \n",
      "48866          388314  2017-01-20             Completed   46863       352841   \n",
      "247835         269945  2017-10-17               Pending    6350       389080   \n",
      "220368         466018  2017-04-13               Pending   26411       867938   \n",
      "313004         666273  2017-04-07             Completed   19758       415216   \n",
      "87138          546336  2017-10-02               Pending    2896       389080   \n",
      "236755         651163  2017-05-23             Completed    9155       365390   \n",
      "298584         775830  2017-03-10                Failed    6818       591642   \n",
      "33183          321230  2017-08-30                Failed   31943       621200   \n",
      "278925         570276  2017-05-19                Failed   45002       847339   \n",
      "251336         468560  2017-03-05                Failed   23737       174408   \n",
      "364890         273256  2017-08-30             Completed   15958       554593   \n",
      "186966         395515  2017-05-19               Pending   48261       638484   \n",
      "271953         613772  2017-05-16                Failed   42766       591642   \n",
      "275056         943192  2017-04-07               Pending   43681       628418   \n",
      "192841         056476  2017-04-17               Pending   15107       628418   \n",
      "143798         865643  2017-06-03               Pending    8480       733572   \n",
      "147476         221016  2017-06-09                Failed   26937       492977   \n",
      "435692         781085  2017-10-17             Completed   37479       289060   \n",
      "411873         299534  2017-07-10             Completed   21790       915790   \n",
      "479224         674674  2017-12-29               Pending    5244        77471   \n",
      "403800         661066  2017-03-10                Failed   18612       114971   \n",
      "73040          082963  2017-11-01                Failed    6382       632251   \n",
      "246787         729563  2017-12-05                Failed    1872       114971   \n",
      "\n",
      "        Holder_id  \n",
      "405253         27  \n",
      "151544         28  \n",
      "426715         21  \n",
      "222061          2  \n",
      "266453         14  \n",
      "335989          6  \n",
      "97388          30  \n",
      "303029         15  \n",
      "75745           2  \n",
      "189429         20  \n",
      "80497          14  \n",
      "124804         24  \n",
      "41887          50  \n",
      "350053         18  \n",
      "315587          9  \n",
      "11952          34  \n",
      "63008          36  \n",
      "403690         43  \n",
      "213659         21  \n",
      "306800          4  \n",
      "306540         31  \n",
      "22531          41  \n",
      "277639         17  \n",
      "435962         19  \n",
      "353425         33  \n",
      "21565          41  \n",
      "195155         26  \n",
      "48866          29  \n",
      "247835         27  \n",
      "220368         50  \n",
      "313004         11  \n",
      "87138          32  \n",
      "236755          7  \n",
      "298584          3  \n",
      "33183           6  \n",
      "278925         40  \n",
      "251336         20  \n",
      "364890         16  \n",
      "186966         33  \n",
      "271953         23  \n",
      "275056          9  \n",
      "192841         29  \n",
      "143798         11  \n",
      "147476          6  \n",
      "435692          3  \n",
      "411873         26  \n",
      "479224         45  \n",
      "403800         22  \n",
      "73040          12  \n",
      "246787         42  \n"
     ]
    }
   ],
   "source": [
    "#working on Transactions Table\n",
    "# I'll be populating some columns from a Andhra_Health_Data.csv and some columns will be generated manually\n",
    "# reference - https://www.kaggle.com/datasets/phiitm/andhra-pradesh-health-data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Read data from Andhra_Health_Data.csv\n",
    "health_data = pd.read_csv('Andhra_Health_Data.csv')\n",
    "\n",
    "# Define lists for customer_id and holder_id\n",
    "customer_ids = [987673, 352841, 554593, 778711, 78932, 319355, 719439, 538409, 979749, 640537,\n",
    "                871428, 847339, 94613, 628418, 974101, 930301, 915790, 389080, 336850, 176254,\n",
    "                638484, 621200, 555849, 972654, 492977, 77471, 289060, 166248, 830875, 591642,\n",
    "                293654, 532909, 109075, 174408, 632251, 981115, 58082, 499661, 950610, 358893,\n",
    "                867938, 114971, 365390, 872585, 144402, 345273, 415216, 733572, 74341, 249650]\n",
    "\n",
    "holder_ids = list(range(1, 51))\n",
    "\n",
    "# Generate random data for other columns\n",
    "num_transactions = len(health_data)\n",
    "transaction_ids = [str(random.randint(0, 999999)).zfill(6) for _ in range(num_transactions)]\n",
    "dates = pd.to_datetime(health_data['CLAIM_DATE']).dt.date\n",
    "status_of_transactions = random.choices(['Completed', 'Pending', 'Failed'], k=num_transactions)\n",
    "amounts = np.random.randint(1000, 50000, num_transactions)\n",
    "customer_ids_random = random.choices(customer_ids, k=num_transactions)\n",
    "holder_ids_random = random.choices(holder_ids, k=num_transactions)\n",
    "\n",
    "# Create the Transactions DataFrame\n",
    "transactions_data = pd.DataFrame({\n",
    "    'Transaction_id': transaction_ids,\n",
    "    'Date': dates,\n",
    "    'status_of_transaction': status_of_transactions,\n",
    "    'Amount': amounts,\n",
    "    'Customer_id': customer_ids_random,\n",
    "    'Holder_id': holder_ids_random\n",
    "})\n",
    "\n",
    "# Save only 50 random rows to a CSV file\n",
    "transactions_data_50_rows = transactions_data.sample(n=50)\n",
    "transactions_data_50_rows.to_csv('Transactions.csv', index=False)\n",
    "\n",
    "# Print or use the resulting DataFrame as needed\n",
    "print(transactions_data_50_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Transaction_id', 'Date', 'status_of_transaction', 'Amount',\n",
       "       'Customer_id', 'Holder_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_data_50_rows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Transactions VALUES (098725,'2017-03-10','Pending',49668,632251,27);\n",
      "INSERT INTO Transactions VALUES (603071,'2017-03-21','Pending',18303,915790,28);\n",
      "INSERT INTO Transactions VALUES (136633,'2017-07-11','Failed',16434,847339,21);\n",
      "INSERT INTO Transactions VALUES (152754,'2017-04-29','Failed',46570,867938,2);\n",
      "INSERT INTO Transactions VALUES (616393,'2017-05-16','Failed',44055,166248,14);\n",
      "INSERT INTO Transactions VALUES (926484,'2017-05-08','Completed',15151,174408,6);\n",
      "INSERT INTO Transactions VALUES (205872,'2017-10-01','Failed',2756,365390,30);\n",
      "INSERT INTO Transactions VALUES (586079,'2017-07-28','Failed',24303,358893,15);\n",
      "INSERT INTO Transactions VALUES (028129,'2017-01-31','Failed',29118,166248,2);\n",
      "INSERT INTO Transactions VALUES (793896,'2017-09-05','Failed',6691,591642,20);\n",
      "INSERT INTO Transactions VALUES (830021,'2017-01-20','Completed',17164,628418,14);\n",
      "INSERT INTO Transactions VALUES (726836,'2017-08-30','Pending',26063,336850,24);\n",
      "INSERT INTO Transactions VALUES (775668,'2017-10-01','Failed',33701,176254,50);\n",
      "INSERT INTO Transactions VALUES (254957,'2017-08-19','Pending',14749,358893,18);\n",
      "INSERT INTO Transactions VALUES (189198,'2017-08-19','Completed',24353,638484,9);\n",
      "INSERT INTO Transactions VALUES (454793,'2017-06-09','Pending',1660,554593,34);\n",
      "INSERT INTO Transactions VALUES (271127,'2017-09-01','Failed',12003,981115,36);\n",
      "INSERT INTO Transactions VALUES (309030,'2017-10-21','Pending',16926,166248,43);\n",
      "INSERT INTO Transactions VALUES (409634,'2017-09-05','Pending',23282,950610,21);\n",
      "INSERT INTO Transactions VALUES (557235,'2017-02-08','Completed',30481,176254,4);\n",
      "INSERT INTO Transactions VALUES (451003,'2017-11-10','Failed',37036,415216,31);\n",
      "INSERT INTO Transactions VALUES (132434,'2017-04-01','Pending',1420,987673,41);\n",
      "INSERT INTO Transactions VALUES (797901,'2017-11-21','Completed',37535,867938,17);\n",
      "INSERT INTO Transactions VALUES (603560,'2017-12-30','Failed',44263,867938,19);\n",
      "INSERT INTO Transactions VALUES (651645,'2017-08-17','Failed',45991,867938,33);\n",
      "INSERT INTO Transactions VALUES (306533,'2017-06-01','Completed',40435,871428,41);\n",
      "INSERT INTO Transactions VALUES (614899,'2017-09-05','Completed',35387,555849,26);\n",
      "INSERT INTO Transactions VALUES (388314,'2017-01-20','Completed',46863,352841,29);\n",
      "INSERT INTO Transactions VALUES (269945,'2017-10-17','Pending',6350,389080,27);\n",
      "INSERT INTO Transactions VALUES (466018,'2017-04-13','Pending',26411,867938,50);\n",
      "INSERT INTO Transactions VALUES (666273,'2017-04-07','Completed',19758,415216,11);\n",
      "INSERT INTO Transactions VALUES (546336,'2017-10-02','Pending',2896,389080,32);\n",
      "INSERT INTO Transactions VALUES (651163,'2017-05-23','Completed',9155,365390,7);\n",
      "INSERT INTO Transactions VALUES (775830,'2017-03-10','Failed',6818,591642,3);\n",
      "INSERT INTO Transactions VALUES (321230,'2017-08-30','Failed',31943,621200,6);\n",
      "INSERT INTO Transactions VALUES (570276,'2017-05-19','Failed',45002,847339,40);\n",
      "INSERT INTO Transactions VALUES (468560,'2017-03-05','Failed',23737,174408,20);\n",
      "INSERT INTO Transactions VALUES (273256,'2017-08-30','Completed',15958,554593,16);\n",
      "INSERT INTO Transactions VALUES (395515,'2017-05-19','Pending',48261,638484,33);\n",
      "INSERT INTO Transactions VALUES (613772,'2017-05-16','Failed',42766,591642,23);\n",
      "INSERT INTO Transactions VALUES (943192,'2017-04-07','Pending',43681,628418,9);\n",
      "INSERT INTO Transactions VALUES (056476,'2017-04-17','Pending',15107,628418,29);\n",
      "INSERT INTO Transactions VALUES (865643,'2017-06-03','Pending',8480,733572,11);\n",
      "INSERT INTO Transactions VALUES (221016,'2017-06-09','Failed',26937,492977,6);\n",
      "INSERT INTO Transactions VALUES (781085,'2017-10-17','Completed',37479,289060,3);\n",
      "INSERT INTO Transactions VALUES (299534,'2017-07-10','Completed',21790,915790,26);\n",
      "INSERT INTO Transactions VALUES (674674,'2017-12-29','Pending',5244,77471,45);\n",
      "INSERT INTO Transactions VALUES (661066,'2017-03-10','Failed',18612,114971,22);\n",
      "INSERT INTO Transactions VALUES (082963,'2017-11-01','Failed',6382,632251,12);\n",
      "INSERT INTO Transactions VALUES (729563,'2017-12-05','Failed',1872,114971,42);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Transactions table\n",
    "for Transaction_id, Date, status_of_transaction, Amount, Customer_id, Holder_id  in transactions_data_50_rows.values.tolist():\n",
    "    print(\"INSERT INTO Transactions VALUES ({},'{}','{}',{},{},{});\".format(Transaction_id, Date, status_of_transaction, Amount, Customer_id, Holder_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
